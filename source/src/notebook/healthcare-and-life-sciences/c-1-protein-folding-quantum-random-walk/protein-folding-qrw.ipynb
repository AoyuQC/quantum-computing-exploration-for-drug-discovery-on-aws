{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./hybridjobs/utility\")\n",
    "\n",
    "from hybridjobs.utility.ProteinParser import ProteinData\n",
    "from hybridjobs.utility.ProteinModel import ProteinModel\n",
    "from hybridjobs.utility.ProteinStructurePrediction import ProteinStructurePrediction\n",
    "import time\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Prepare Data\n",
    "\n",
    "In this part, we have prepared the precalculated energies files in advance for doing protein folding experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: aminoacids\n",
    "# output: energy files\n",
    "\n",
    "protein_name = 'glycylglycine'\n",
    "aminoacids = 'GG'\n",
    "number_bits_to_discretize_protein_angles = 4\n",
    "protein_id = 0\n",
    "\n",
    "data_path='protein-folding-data'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Build Model\n",
    "\n",
    "In this part, we will show how to build model for qfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initial parameters for protein glycylglycine_3_GG using qfold-cc\n",
      "INFO:root:Initial parameters for protein glycylglycine_3_GG using qfold-qc\n",
      "INFO:root:Initial parameters for protein glycylglycine_4_GG using qfold-cc\n",
      "INFO:root:Initial parameters for protein glycylglycine_4_GG using qfold-qc\n"
     ]
    }
   ],
   "source": [
    "# initial the ProteinFold object\n",
    "init_param = {}\n",
    "# method: qfold-cc stands for the classical metropolis method in QFold\n",
    "# method: qfold-qc stands for the quantum metropolis method in QFold\n",
    "method = ['qfold-cc', 'qfold-qc']\n",
    "\n",
    "for mt in method:\n",
    "    if mt == 'qfold-cc':\n",
    "        init_param[mt] = {}\n",
    "        init_param[mt]['params'] = [\"initialization\"]\n",
    "    elif mt == 'qfold-qc':\n",
    "        init_param[mt] = {}\n",
    "        init_param[mt]['params'] = [\"initialization\"]\n",
    "\n",
    "config_path = \"hybridjobs/config/config.json\"\n",
    "protein_model = ProteinModel(data_path, method, config_path, **init_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deltas_dict length for glycylglycine_3_GG: 256\n",
      "deltas_dict length for glycylglycine_3_GG: 256\n",
      "deltas_dict length for glycylglycine_4_GG: 1024\n",
      "deltas_dict length for glycylglycine_4_GG: 1024\n",
      "deltas_dict length for glycylglycine_3_GG: 256\n",
      "deltas_dict length for glycylglycine_3_GG: 256\n",
      "deltas_dict length for glycylglycine_4_GG: 1024\n",
      "deltas_dict length for glycylglycine_4_GG: 1024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the parameters for model\n",
    "model_param = {}\n",
    "\n",
    "method = 'qfold-cc'\n",
    "model_param[method] = {}\n",
    "\n",
    "# parameters\n",
    "model_param[method]['initialization'] = [\"minifold\", \"random\"]\n",
    "\n",
    "method = 'qfold-qc'\n",
    "model_param[method] = {}\n",
    "\n",
    "# parameters\n",
    "model_param[method]['initialization'] = [\"minifold\", \"random\"]\n",
    "\n",
    "protein_model.build_models(**model_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:finish save protein_folding_latest.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have built the protein folding models and saved them as protein_folding_latest.pickle\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "model_path = protein_model.save(\"latest\")\n",
    "\n",
    "print(f\"You have built the protein folding models and saved them as protein_folding_latest.pickle\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Predict Protein Structure\n",
    "\n",
    "In this part, we will show how to run models for predicting protein structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_models = ProteinModel.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:debug describe\n",
      "INFO:root:model name: glycylglycine_3_GG, method: qfold-cc\n",
      "INFO:root:param: initialization, value {'random', 'minifold'}\n",
      "INFO:root:model name: glycylglycine_3_GG, method: qfold-qc\n",
      "INFO:root:param: initialization, value {'random', 'minifold'}\n",
      "INFO:root:model name: glycylglycine_4_GG, method: qfold-cc\n",
      "INFO:root:param: initialization, value {'random', 'minifold'}\n",
      "INFO:root:model name: glycylglycine_4_GG, method: qfold-qc\n",
      "INFO:root:param: initialization, value {'random', 'minifold'}\n"
     ]
    }
   ],
   "source": [
    "model_info = protein_models.describe_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model you want to optimize\n",
    "protein_name = 'glycylglycine_3_GG'\n",
    "initialization = 'random'\n",
    "method = 'qfold-cc'\n",
    "\n",
    "model_name = \"{}+{}\".format(protein_name, initialization)\n",
    "\n",
    "protein_model = protein_models.get_model(protein_name, method, model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:initial protein structure prediction using qfold-cc in QFold\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 2 steps: 0.3035731315612793 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 3 steps: 0.42159223556518555 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 4 steps: 0.5437848567962646 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 5 steps: 0.668097734451294 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 6 steps: 0.8060107231140137 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 7 steps: 0.9142270088195801 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 8 steps: 1.0407094955444336 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 9 steps: 1.1587982177734375 seconds\n",
      "INFO:root:finish save tts_results_glycylglycine_3_GG+random_1000_qfold-cc.json\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "# psp_param stands for the parameters for predicting protein structure\n",
    "psp_param = {}\n",
    "psp_param[\"data_path\"] = data_path\n",
    "psp_param[\"mode\"] = 'local-simulator'\n",
    "psp_param[\"model_name\"] = model_name\n",
    "psp_param[\"model_path\"] = model_path\n",
    "\n",
    "psp = ProteinStructurePrediction(protein_model, method, config_path, **psp_param)\n",
    "\n",
    "psp.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialization = 'random'\n",
    "method = 'qfold-qc'\n",
    "\n",
    "model_name = \"{}+{}\".format(protein_name, initialization)\n",
    "\n",
    "protein_model = protein_models.get_model(protein_name, method, model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:initial protein structure prediction using qfold-qc in QFold\n",
      "INFO:qiskit.compiler.assembler:Total Assembly Time - 0.10800 (ms)\n",
      "INFO:qiskit.compiler.assembler:Total Assembly Time - 0.05174 (ms)\n",
      "INFO:qiskit.compiler.assembler:Total Assembly Time - 0.04840 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnitarySynthesis - 0.01073 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnrollCustomDefinitions - 27500.04935 (ms)\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Begin BasisTranslator from source basis {('ccx', 3), ('mcx', 5), ('cx', 2), ('mcx', 4), ('mcu1', 9), ('snapshot', 16), ('cu3', 2), ('x', 1), ('h', 1)} to target basis {'save_expval', 'barrier', 'mcrx', 'ryy', 'cu3', 'roerror', 'mcz', 'cu', 'measure', 'delay', 'mcr', 'rzz', 'sdg', 'save_state', 'cy', 'rzx', 'unitary', 'mcphase', 'qerror_loc', 'save_probs_ket', 'cu1', 'initialize', 't', 'z', 'cswap', 'ry', 'u', 'sxdg', 'h', 'csx', 'id', 'mcry', 'swap', 'kraus', 'p', 'r', 'rx', 'cx', 'mcp', 'mcu3', 'rxx', 'save_probs', 'set_statevector', 'save_amplitudes_sq', 'mcx', 'snapshot', 'mcswap', 'u2', 'u1', 'ccx', 'mcu', 'cz', 'tdg', 'sx', 'mcrz', 'y', 'multiplexer', 'mcu1', 'reset', 'mcy', 'cu2', 'save_amplitudes', 'u3', 'save_density_matrix', 'diagonal', 'rz', 'save_statevector', 'pauli', 'cp', 'mcu2', 'quantum_channel', 'x', 's', 'mcsx'}.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation path search completed in 0.000s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation paths composed in 0.096s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation instructions replaced in 0.414s.\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: BasisTranslator - 680.49669 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: RemoveResetInZeroState - 33.23388 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: Depth - 35.45284 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: FixedPoint - 0.01335 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: Optimize1qGatesDecomposition - 36900.12527 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: CXCancellation - 47.61624 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnitarySynthesis - 0.01121 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnrollCustomDefinitions - 77.10648 (ms)\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Begin BasisTranslator from source basis {('ccx', 3), ('u3', 1), ('mcx', 5), ('cx', 2), ('mcx', 4), ('mcu1', 9), ('snapshot', 16), ('cu3', 2), ('u2', 1), ('x', 1), ('h', 1)} to target basis {'save_expval', 'barrier', 'mcrx', 'ryy', 'cu3', 'roerror', 'mcz', 'cu', 'measure', 'delay', 'mcr', 'rzz', 'sdg', 'save_state', 'cy', 'rzx', 'unitary', 'mcphase', 'qerror_loc', 'save_probs_ket', 'cu1', 'initialize', 't', 'z', 'cswap', 'ry', 'u', 'sxdg', 'h', 'csx', 'id', 'mcry', 'swap', 'kraus', 'p', 'r', 'rx', 'cx', 'mcp', 'mcu3', 'rxx', 'save_probs', 'set_statevector', 'save_amplitudes_sq', 'mcx', 'snapshot', 'mcswap', 'u2', 'u1', 'ccx', 'mcu', 'cz', 'tdg', 'sx', 'mcrz', 'y', 'multiplexer', 'mcu1', 'reset', 'mcy', 'cu2', 'save_amplitudes', 'u3', 'save_density_matrix', 'diagonal', 'rz', 'save_statevector', 'pauli', 'cp', 'mcu2', 'quantum_channel', 'x', 's', 'mcsx'}.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation path search completed in 0.000s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation paths composed in 0.043s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation instructions replaced in 0.201s.\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: BasisTranslator - 308.18915 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: Depth - 18.19110 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: FixedPoint - 0.01192 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: Optimize1qGatesDecomposition - 7874.60780 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: CXCancellation - 47.97244 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnitarySynthesis - 0.01121 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnrollCustomDefinitions - 77.09765 (ms)\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Begin BasisTranslator from source basis {('ccx', 3), ('u3', 1), ('mcx', 5), ('cx', 2), ('mcx', 4), ('mcu1', 9), ('snapshot', 16), ('cu3', 2), ('u2', 1), ('x', 1), ('h', 1)} to target basis {'save_expval', 'barrier', 'mcrx', 'ryy', 'cu3', 'roerror', 'mcz', 'cu', 'measure', 'delay', 'mcr', 'rzz', 'sdg', 'save_state', 'cy', 'rzx', 'unitary', 'mcphase', 'qerror_loc', 'save_probs_ket', 'cu1', 'initialize', 't', 'z', 'cswap', 'ry', 'u', 'sxdg', 'h', 'csx', 'id', 'mcry', 'swap', 'kraus', 'p', 'r', 'rx', 'cx', 'mcp', 'mcu3', 'rxx', 'save_probs', 'set_statevector', 'save_amplitudes_sq', 'mcx', 'snapshot', 'mcswap', 'u2', 'u1', 'ccx', 'mcu', 'cz', 'tdg', 'sx', 'mcrz', 'y', 'multiplexer', 'mcu1', 'reset', 'mcy', 'cu2', 'save_amplitudes', 'u3', 'save_density_matrix', 'diagonal', 'rz', 'save_statevector', 'pauli', 'cp', 'mcu2', 'quantum_channel', 'x', 's', 'mcsx'}.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation path search completed in 0.000s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation paths composed in 0.043s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation instructions replaced in 0.201s.\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: BasisTranslator - 306.87308 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: Depth - 18.50057 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: FixedPoint - 0.01264 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: Optimize1qGatesDecomposition - 7755.74756 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: CXCancellation - 48.16389 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnitarySynthesis - 0.01049 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnrollCustomDefinitions - 77.50750 (ms)\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Begin BasisTranslator from source basis {('ccx', 3), ('u3', 1), ('mcx', 5), ('cx', 2), ('mcx', 4), ('mcu1', 9), ('snapshot', 16), ('cu3', 2), ('u2', 1), ('x', 1), ('h', 1)} to target basis {'save_expval', 'barrier', 'mcrx', 'ryy', 'cu3', 'roerror', 'mcz', 'cu', 'measure', 'delay', 'mcr', 'rzz', 'sdg', 'save_state', 'cy', 'rzx', 'unitary', 'mcphase', 'qerror_loc', 'save_probs_ket', 'cu1', 'initialize', 't', 'z', 'cswap', 'ry', 'u', 'sxdg', 'h', 'csx', 'id', 'mcry', 'swap', 'kraus', 'p', 'r', 'rx', 'cx', 'mcp', 'mcu3', 'rxx', 'save_probs', 'set_statevector', 'save_amplitudes_sq', 'mcx', 'snapshot', 'mcswap', 'u2', 'u1', 'ccx', 'mcu', 'cz', 'tdg', 'sx', 'mcrz', 'y', 'multiplexer', 'mcu1', 'reset', 'mcy', 'cu2', 'save_amplitudes', 'u3', 'save_density_matrix', 'diagonal', 'rz', 'save_statevector', 'pauli', 'cp', 'mcu2', 'quantum_channel', 'x', 's', 'mcsx'}.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation path search completed in 0.000s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation paths composed in 0.042s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation instructions replaced in 0.200s.\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: BasisTranslator - 305.28092 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: ContainsInstruction - 0.00763 (ms)\n",
      "INFO:qiskit.compiler.transpiler:Total Transpile Time - 84891.31880 (ms)\n",
      "INFO:qiskit.compiler.assembler:Total Assembly Time - 0.12660 (ms)\n",
      "INFO:qiskit.execute_function:Total Job Submission Time - 348.64831 (ms)\n",
      "INFO:root:QUANTUM METROPOLIS: Time for final steps 91.13613080978394 seconds (87.01234769821167 seconds statevector)\n",
      "INFO:root:finish save tts_results_glycylglycine_3_GG+random_1000_qfold-qc.json\n"
     ]
    }
   ],
   "source": [
    "psp = ProteinStructurePrediction(protein_model, method, config_path, **psp_param)\n",
    "\n",
    "psp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The min tts for classical method is 61.902315133723086, for quantum method is 125.83909728469\n"
     ]
    }
   ],
   "source": [
    "# The time for final steps can be compared among these two methods\n",
    "import json\n",
    "\n",
    "with open(\"tts_results_glycylglycine_3_GG+random_1000_qfold-cc.json\") as f:\n",
    "    qfold_cc_results = json.load(f)\n",
    "\n",
    "with open(\"tts_results_glycylglycine_3_GG+random_1000_qfold-qc.json\") as f:\n",
    "    qfold_qc_results = json.load(f)\n",
    "\n",
    "qfold_cc_min_tts = qfold_cc_results['final_stats']['min_tts']['value']\n",
    "qfold_qc_min_tts = qfold_qc_results['final_stats']['min_tts']['value']\n",
    "print(f\"The min tts for classical method is {qfold_cc_min_tts}, for quantum method is {qfold_qc_min_tts}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Job Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "from braket.aws import AwsDevice\n",
    "from braket.aws import AwsQuantumJob, AwsSession\n",
    "from braket.jobs.config import InstanceConfig\n",
    "from hybridjobs.utility.HybridJobHelpers import *\n",
    "\n",
    "import boto3\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Prepare parameters for batch evaluation\n",
    "\n",
    "In this part, we set the parameters for batch evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters for experiments: \n",
      " [{'method': 'qfold-cc', 'initialization': 'minifold', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'method': 'qfold-cc', 'initialization': 'minifold', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}, {'method': 'qfold-cc', 'initialization': 'random', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'method': 'qfold-cc', 'initialization': 'random', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}, {'method': 'qfold-qc', 'initialization': 'minifold', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'method': 'qfold-qc', 'initialization': 'minifold', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}, {'method': 'qfold-qc', 'initialization': 'random', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'method': 'qfold-qc', 'initialization': 'random', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}]\n"
     ]
    }
   ],
   "source": [
    "# parameters for experiments\n",
    "experiment_name = \"protein-folding-qrw\"\n",
    "data_path = \"protein-folding-data\"\n",
    "suffix_check = [\"json\"]\n",
    "experiments_params =  {\n",
    "    \"version\": \"1\",\n",
    "    \"params\": [\n",
    "        {\"method\": [\"qfold-cc\", \"qfold-qc\"]},\n",
    "        {\"initialization\": [\"minifold\", \"random\"]},\n",
    "        {\"shots\": [10000]},\n",
    "        {\"mode\": [\"local-simulator\"]},\n",
    "        {\"device\": [{\"qc\": \"null\", \"cc\": \"ml.m5.large\"},{\"qc\": \"null\", \"cc\": \"ml.m5.4xlarge\"}]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "hp = {}\n",
    "hybrid_job_params = []\n",
    "parse_params(experiments_params['params'], hp, hybrid_job_params)\n",
    "\n",
    "print(f\"parameters for experiments: \\n {hybrid_job_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload data to s3 path: s3://amazon-braket-us-east-1-002224604296/protein-folding-data\n"
     ]
    }
   ],
   "source": [
    "# Upload dataset to S3\n",
    "s3_path = upload_data(data_path)\n",
    "print(f\"upload data to s3 path: {s3_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Prepare image for experiment\n",
    "\n",
    "In this part, we use the following code to prepare the image for experiment. For the first run, \n",
    "please run build_and_push.sh to create the image. For future experiments, avoid running\n",
    "build_and_push.sh unless you want to rebuild the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the hybrid job image for 002224604296 in region us-east-1: 002224604296.dkr.ecr.us-east-1.amazonaws.com/amazon-braket-qfoldhybridjobs-jobs:latest\n",
      "WARNING! Your password will be stored unencrypted in /home/ubuntu/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "WARNING! Your password will be stored unencrypted in /home/ubuntu/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "Sending build context to Docker daemon  196.5MB\n",
      "Step 1/4 : FROM 292282985366.dkr.ecr.us-west-2.amazonaws.com/amazon-braket-base-jobs:1.0-cpu-py37-ubuntu18.04\n",
      " ---> 16b9ec942e00\n",
      "Step 2/4 : RUN python3 -m pip install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> 11a512e96ae1\n",
      "Step 3/4 : RUN python3 -m pip install numpy==1.19.5                             scipy==1.5.4                             tensorflow==1.15.0                             Keras==2.0.8                             qiskit==0.34.2                             qiskit-aer==0.10.3                             qiskit-aqua==0.9.5                             qiskit-ibmq-provider==0.18.3                             qiskit-ignis==0.7.0                             qiskit-terra==0.19.2                             matplotlib==3.3.4                             bokeh==2.3.3\n",
      " ---> Using cache\n",
      " ---> 13586942fb6c\n",
      "Step 4/4 : COPY QfoldHybridJobs/psi4 /home/ubuntu/psi4conda/bin/psi4\n",
      "COPY failed: file not found in build context or excluded by .dockerignore: stat QfoldHybridJobs/psi4: file does not exist\n",
      "The push refers to repository [002224604296.dkr.ecr.us-east-1.amazonaws.com/amazon-braket-qfoldhybridjobs-jobs]\n",
      "\n",
      "\u001b[1Bb87c7786: Preparing \n",
      "\u001b[1B4b37a5e5: Preparing \n",
      "\u001b[1Bb90ba34e: Preparing \n",
      "\u001b[1B6411a7d1: Preparing \n",
      "\u001b[1B56d89649: Preparing \n",
      "\u001b[1B148e4f08: Preparing \n",
      "\u001b[1B0f2f3775: Preparing \n",
      "\u001b[1Ba5237a47: Preparing \n",
      "\u001b[1B7b584848: Preparing \n",
      "\u001b[1B9cc6ed2d: Preparing \n",
      "\u001b[1B9ba03cb5: Preparing \n",
      "\u001b[1B3dae4964: Preparing \n",
      "\u001b[1B0cee8562: Preparing \n",
      "\u001b[1Bc13d298e: Preparing \n",
      "\u001b[1B2ecf6ff1: Preparing \n",
      "\u001b[1B5cb74c43: Preparing \n",
      "\u001b[1B49c05c79: Preparing \n",
      "\u001b[1Bb7118beb: Preparing \n",
      "\u001b[2Bb7118beb: Layer already exists \u001b[17A\u001b[2K\u001b[13A\u001b[2K\u001b[9A\u001b[2K\u001b[4A\u001b[2Klatest: digest: sha256:1a877030701ca61df80af35d9fe5f88c96703205e407de3f12b0771e8d7a1023 size: 4313\n"
     ]
    }
   ],
   "source": [
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = boto3.client('s3').meta.region_name\n",
    "image_name = f\"amazon-braket-{experiment_name.lower()}-jobs\"\n",
    "image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{image_name}:latest\"\n",
    "\n",
    "print(f\"the hybrid job image for {account_id} in region {region}: {image_uri}\")\n",
    "\n",
    "# For the first run, please use the following code to create the image for this application. For future experiments, comment\n",
    "# the following code unless you want to rebuild the image\n",
    "!sh build_and_push.sh {image_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job info will be saved in QfoldHybridJobs-hybrid-jobs.json\n"
     ]
    }
   ],
   "source": [
    "hybrid_jobs_json = f\"{experiment_name}-hybrid-jobs.json\"\n",
    "print(f\"job info will be saved in {hybrid_jobs_json}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Launch Amazon Braket Hybrid Jobs for experiment\n",
    "\n",
    "In this part, we use the following code to launch the same number of hybrid jobs as the sets of parameters for this experiments.\n",
    "When the number of jobs exceeds 5 RPS, this thread will wait. The default setting of this experiment will take around **7 hours** to \n",
    "finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fail to get null: list index out of range, use sv1 instead\n",
      "name is q-m-l-ml-m5-large-1685443519\n",
      "Finish create protein-folding-qrw with q-m-l-ml-m5-large-1685443519\n"
     ]
    }
   ],
   "source": [
    "# Long runnning cell due to Burst rate of CreateJob requests < 5 RPS\n",
    "# sudo apt-get install python-prctl at first\n",
    "# https://stackoverflow.com/questions/34361035/python-thread-name-doesnt-show-up-on-ps-or-htop\n",
    "from threading import Thread\n",
    "import threading\n",
    "import setproctitle\n",
    "\n",
    "def launch_hybrid_jobs(hybrid_job_params=hybrid_job_params, hybrid_jobs_json=hybrid_jobs_json):\n",
    "    setproctitle.setproctitle(threading.current_thread().name)\n",
    "    # parse evaluation parameters and trigger hybrid jobs:\n",
    "    jobs = []\n",
    "    names = []\n",
    "\n",
    "    job_name = f\"{experiment_name}-job\"\n",
    "    device_param_list = [\"shots\", \"device\"]\n",
    "\n",
    "    for job_param in hybrid_job_params:\n",
    "        \n",
    "        algorithm_param_name = \"\"\n",
    "        for k,v in job_param.items():\n",
    "            if k not in device_param_list:\n",
    "                algorithm_param_name = algorithm_param_name+f\"-{v[0]}\"\n",
    "        algorithm_param_name=algorithm_param_name[1:]\n",
    "        quantum_device = get_quantum_device(job_param['device']['qc'])\n",
    "        classical_device = job_param['device']['cc']\n",
    "\n",
    "        device_name = classical_device.replace(\".\",\"-\")\n",
    "        device_name = device_name.replace(\"x\",\"\")\n",
    "        \n",
    "        name = f\"{algorithm_param_name}-{device_name}-\" + str(int(time.time()))\n",
    "        name = name.lower()\n",
    "        # name = f\"{experiment_name}-\"+ str(int(time.time()))\n",
    "        print(f\"name is {name}\")\n",
    "\n",
    "        tmp_job = AwsQuantumJob.create(\n",
    "            device=quantum_device,\n",
    "            source_module=\"hybridjobs\",\n",
    "            entry_point=f\"hybridjobs.{job_name}:main\",\n",
    "            job_name=name,\n",
    "            hyperparameters=job_param,\n",
    "            input_data=s3_path,\n",
    "            instance_config=InstanceConfig(instanceType=classical_device),\n",
    "            image_uri=image_uri,\n",
    "            wait_until_complete=False,\n",
    "        )\n",
    "        \n",
    "#         from braket.jobs.local import LocalQuantumJob\n",
    "        \n",
    "#         tmp_job = LocalQuantumJob.create(\n",
    "#             device=quantum_device,\n",
    "#             source_module=f\"{experiment_name}\",\n",
    "#             entry_point=f\"{experiment_name}.{job_name}:main\",\n",
    "#             hyperparameters=job_param,\n",
    "#             input_data=s3_path,\n",
    "#             image_uri=image_uri,\n",
    "#         )   \n",
    "        \n",
    "        print(f\"Finish create {experiment_name} with {name}\")\n",
    "\n",
    "        jobs.append(tmp_job)\n",
    "        names.append(name)\n",
    "\n",
    "\n",
    "        while not queue_check(jobs):\n",
    "            time.sleep(5)\n",
    "    jobs_arn = []\n",
    "\n",
    "    for job in jobs:\n",
    "        jobs_arn.append(job.arn)\n",
    "\n",
    "    jobs_states = {\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"hybrid-jobs-arn\": jobs_arn,\n",
    "        \"names\": names\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # save hybrid job arn for further analysis\n",
    "    json_object = json.dumps(jobs_states, indent=4)\n",
    "\n",
    "    with open(hybrid_jobs_json, \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "        \n",
    "    print(f\"Finish launch all the hybrid jobs and save all the files\")\n",
    "\n",
    "# remove existing hybrid_jobs_json file\n",
    "!rm {hybrid_jobs_json}\n",
    "\n",
    "t = Thread(target=launch_hybrid_jobs, name=\"launch-hybrid-job\", daemon=True).start()\n",
    "\n",
    "# launch_hybrid_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ubuntu     77570  0.3  2.3 5040324 744808 ?      Sl   May29   2:07 launch-hybrid-job\n",
      "ubuntu     84470  0.0  0.0   8756  3484 pts/1    Ss+  10:52   0:00 /bin/bash -c ps -aux | grep launch-hybrid-job\n",
      "ubuntu     84475  0.0  0.0   8176   724 pts/1    S+   10:52   0:00 grep launch-hybrid-job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 3 jobs in RUNNING or QUEUED status\n",
      "Finish launch all the hybrid jobs and save all the files\n"
     ]
    }
   ],
   "source": [
    "# run the following scripts to check the created threads\n",
    "!ps -aux | grep launch-hybrid-job"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Jobs finish and visualize results\n",
    "\n",
    "Please use the following code to check the status of hybrid jobs. The status of hybrid jobs can also be checked in the Amazon Braket console. Optionally, if the email if input when deploying the solution, emails will be sent at the same number of hybrid jobs once \n",
    "the status of jobs changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the state of job q-m-l-ml-m5-large-1685443519 is : COMPLETED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the state of job q-m-l-ml-m5-4large-1685443528 is : COMPLETED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the state of job q-r-l-ml-m5-large-1685443537 is : COMPLETED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the state of job q-r-l-ml-m5-4large-1685443545 is : COMPLETED\n",
      "the state of job q-m-l-ml-m5-large-1685443728 is : COMPLETED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the state of job q-m-l-ml-m5-4large-1685443737 is : COMPLETED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the state of job q-r-l-ml-m5-large-1685443775 is : COMPLETED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the state of job q-r-l-ml-m5-4large-1685443794 is : COMPLETED\n",
      "all jobs completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precalculated_energies': {}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precalculated_energies': {}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precalculated_energies': {}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precalculated_energies': {}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precalculated_energies': {}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precalculated_energies': {}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precalculated_energies': {}}\n",
      "{'precalculated_energies': {}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'hypermeter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_77570/1085639916.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# display results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisplay_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiments_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"JSON file for job arns not generated! please wait for the thread(launch-hybrid-job) to finish\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workplace/csdc/quantum-computing-exploration-for-drug-discovery-on-aws/source/src/notebook/healthcare-and-life-sciences/c-1-protein-folding-quantum-random-walk/hybridjobs/utility/HybridJobHelpers.py\u001b[0m in \u001b[0;36mdisplay_results\u001b[0;34m(results, experiments_params)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hypermeter\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'hypermeter'"
     ]
    }
   ],
   "source": [
    "# run the following code to test whether all the jobs finish\n",
    "results = []\n",
    "if os.path.exists(hybrid_jobs_json):\n",
    "    # recover hybrid jobs and show result\n",
    "    jobs_states_load = None\n",
    "    with open(hybrid_jobs_json, \"r\") as outfile:\n",
    "        jobs_states_load = json.load(outfile)\n",
    "\n",
    "    completed_jobs_arn = set()\n",
    "\n",
    "    for job_name, job_arn in zip(jobs_states_load[\"names\"], jobs_states_load[\"hybrid-jobs-arn\"]):\n",
    "        current_job = AwsQuantumJob(job_arn)\n",
    "        print(f\"the state of job {job_name} is : {current_job.state()}\")\n",
    "        if current_job.state() == 'COMPLETED':\n",
    "            completed_jobs_arn.update({job_arn})\n",
    "\n",
    "    whole_jobs_num = len(jobs_states_load[\"names\"])\n",
    "\n",
    "    if len(completed_jobs_arn) == whole_jobs_num:\n",
    "        print(f\"all jobs completed\")\n",
    "        for job_arn in completed_jobs_arn:\n",
    "            current_job = AwsQuantumJob(job_arn)\n",
    "            results.append(current_job.result())\n",
    "            print(current_job.result())\n",
    "        # display results\n",
    "        results = display_results(results, experiments_params)\n",
    "else:\n",
    "    print(f\"JSON file for job arns not generated! please wait for the thread(launch-hybrid-job) to finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'precalculated_energies': {}},\n",
       " {'precalculated_energies': {}},\n",
       " {'precalculated_energies': {}},\n",
       " {'precalculated_energies': {}},\n",
       " {'precalculated_energies': {}},\n",
       " {'precalculated_energies': {}},\n",
       " {'precalculated_energies': {}},\n",
       " {'precalculated_energies': {}}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-11-d520545c3318>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[0mx_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[0my_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\'\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      7\u001b[0m     \u001b[0mdict_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fail to get null: list index out of range, use sv1 instead\n",
      "name is qfold-cc-minifold-local-simulator-ml-m5-large-1679452955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread launch-hybrid-job:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/qfold-python3.7/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/qfold-python3.7/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-8-13347a113ad7>\", line 44, in launch_hybrid_jobs\n",
      "    wait_until_complete=False,\n",
      "  File \"/opt/conda/envs/qfold-python3.7/lib/python3.7/site-packages/braket/aws/aws_quantum_job.py\", line 198, in create\n",
      "    job_arn = aws_session.create_job(**create_job_kwargs)\n",
      "  File \"/opt/conda/envs/qfold-python3.7/lib/python3.7/site-packages/braket/aws/aws_session.py\", line 244, in create_job\n",
      "    response = self.braket_client.create_job(**boto3_kwargs)\n",
      "  File \"/opt/conda/envs/qfold-python3.7/lib/python3.7/site-packages/botocore/client.py\", line 508, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/opt/conda/envs/qfold-python3.7/lib/python3.7/site-packages/botocore/client.py\", line 911, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.exceptions.ClientError: An error occurred (BadRequestException) when calling the CreateJob operation: Invalid request body\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rename_result = {}\n",
    "device_list = []\n",
    "x_list = []\n",
    "y_list = []\n",
    "for k,vs in results.items():\n",
    "    k = k.replace(\"\\'\",\"\\\"\")\n",
    "    dict_k = json.loads(k)\n",
    "    device_name = None\n",
    "    if dict_k['qc'] == 'null':\n",
    "        device_name = dict_k['cc']\n",
    "    else:\n",
    "        device_name = dict_k['qc']\n",
    "    for v in vs:\n",
    "        device_list.append(device_name)\n",
    "        x_list.append(v[0])\n",
    "        y_list.append(v[1])\n",
    "source = pd.DataFrame({\n",
    "    \"Sequence Length\": np.array(x_list),\n",
    "    \"Time to Solution\": np.array(y_list),\n",
    "    \"Device\": np.array(device_list),\n",
    "})\n",
    "\n",
    "alt.Chart(source).mark_line(point = True).encode(\n",
    "    x='Sequence Length',\n",
    "    y='Time to Solution',\n",
    "    color='Device',\n",
    ").properties(\n",
    "    title = f\"{experiment_name} experiments\",\n",
    "    width = 700,\n",
    "    height = 600,\n",
    ").interactive()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
