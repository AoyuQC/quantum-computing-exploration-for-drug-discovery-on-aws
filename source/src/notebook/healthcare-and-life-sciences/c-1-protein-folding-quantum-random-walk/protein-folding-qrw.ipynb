{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm Explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./hybridjobs/utility\")\n",
    "\n",
    "from hybridjobs.utility.ProteinParser import ProteinData\n",
    "from hybridjobs.utility.ProteinModel import ProteinModel\n",
    "from hybridjobs.utility.ProteinStructurePrediction import ProteinStructurePrediction\n",
    "# from utility.ResultProcess import ResultParser\n",
    "import time\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Prepare Data\n",
    "\n",
    "In this part, we load the folder with the raw rna data for experimentation. To evaluate the quantum solution and the actual solution include both fasta and ct files. To only generate a quantum solution, upload a fasta file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: aminoacids\n",
    "# output: energy files\n",
    "\n",
    "protein_name = 'glycylglycine'\n",
    "aminoacids = 'GG'\n",
    "number_bits_to_discretize_protein_angles = 4\n",
    "protein_id = 0\n",
    "\n",
    "input_filename = \"inputRotations\"\n",
    "output_filename = \"outputRotations\"\n",
    "basis = \"6-31g\"\n",
    "energy_method = \"mp2\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='protein-folding-data'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Build Model\n",
    "\n",
    "In this part, we will show how to build model for qfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initial parameters for protein glycylglycine_3_GG using qfold-cc\n",
      "INFO:root:Initial parameters for protein glycylglycine_3_GG using qfold-qc\n",
      "INFO:root:Initial parameters for protein glycylglycine_4_GG using qfold-cc\n",
      "INFO:root:Initial parameters for protein glycylglycine_4_GG using qfold-qc\n"
     ]
    }
   ],
   "source": [
    "# initial the ProteinFold object\n",
    "init_param = {}\n",
    "# method: qfold-cc stands for the classical metropolis method in QFold\n",
    "# method: qfold-qc stands for the quantum metropolis method in QFold\n",
    "method = ['qfold-cc', 'qfold-qc']\n",
    "\n",
    "for mt in method:\n",
    "    if mt == 'qfold-cc':\n",
    "        init_param[mt] = {}\n",
    "        init_param[mt]['params'] = [\"initialization\"]\n",
    "    elif mt == 'qfold-qc':\n",
    "        init_param[mt] = {}\n",
    "        init_param[mt]['params'] = [\"initialization\"]\n",
    "\n",
    "config_path = \"ProteinFoldingHybridJobs/config/config.json\"\n",
    "protein_model = ProteinModel(data_path, method, config_path, **init_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deltas_dict length for glycylglycine_3_GG: 256\n",
      "deltas_dict length for glycylglycine_3_GG: 256\n",
      "deltas_dict length for glycylglycine_4_GG: 1024\n",
      "deltas_dict length for glycylglycine_4_GG: 1024\n",
      "deltas_dict length for glycylglycine_3_GG: 256\n",
      "deltas_dict length for glycylglycine_3_GG: 256\n",
      "deltas_dict length for glycylglycine_4_GG: 1024\n",
      "deltas_dict length for glycylglycine_4_GG: 1024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the parameters for model\n",
    "model_param = {}\n",
    "\n",
    "method = 'qfold-cc'\n",
    "model_param[method] = {}\n",
    "\n",
    "# parameters\n",
    "model_param[method]['initialization'] = [\"minifold\", \"random\"]\n",
    "\n",
    "method = 'qfold-qc'\n",
    "model_param[method] = {}\n",
    "\n",
    "# parameters\n",
    "model_param[method]['initialization'] = [\"minifold\", \"random\"]\n",
    "\n",
    "protein_model.build_models(**model_param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:finish save protein_folding_latest.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have built the protein folding models and saved them as protein_folding_latest.pickle\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "model_path = protein_model.save(\"latest\")\n",
    "\n",
    "print(f\"You have built the protein folding models and saved them as protein_folding_latest.pickle\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Predict Protein Structure\n",
    "\n",
    "In this part, we will show how to run models for predicting protein structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_models = ProteinModel.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:debug describe\n",
      "INFO:root:model name: glycylglycine_3_GG, method: qfold-cc\n",
      "INFO:root:param: initialization, value {'minifold', 'random'}\n",
      "INFO:root:model name: glycylglycine_3_GG, method: qfold-qc\n",
      "INFO:root:param: initialization, value {'minifold', 'random'}\n",
      "INFO:root:model name: glycylglycine_4_GG, method: qfold-cc\n",
      "INFO:root:param: initialization, value {'minifold', 'random'}\n",
      "INFO:root:model name: glycylglycine_4_GG, method: qfold-qc\n",
      "INFO:root:param: initialization, value {'minifold', 'random'}\n"
     ]
    }
   ],
   "source": [
    "model_info = protein_models.describe_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model you want to optimize\n",
    "protein_name = 'glycylglycine_3_GG'\n",
    "initialization = 'random'\n",
    "method = 'qfold-cc'\n",
    "\n",
    "model_name = \"{}+{}\".format(protein_name, initialization)\n",
    "\n",
    "protein_model = protein_models.get_model(protein_name, method, model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:initial protein structure prediction using qfold-cc in QFold\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 2 steps: 0.3307058811187744 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 3 steps: 0.46265339851379395 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 4 steps: 0.6084005832672119 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 5 steps: 0.7418649196624756 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 6 steps: 0.8906919956207275 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 7 steps: 1.020871877670288 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 8 steps: 1.1487469673156738 seconds\n",
      "INFO:root:CLASSICAL METROPOLIS: Time for 9 steps: 1.298386812210083 seconds\n",
      "INFO:root:finish save tts_results_glycylglycine_3_GG+random_1000_qfold-cc.json\n"
     ]
    }
   ],
   "source": [
    "data_path = 'data'\n",
    "# psp_param stands for the parameters for predicting protein structure\n",
    "psp_param = {}\n",
    "psp_param[\"data_path\"] = data_path\n",
    "psp_param[\"mode\"] = 'local-simulator'\n",
    "psp_param[\"model_name\"] = model_name\n",
    "psp_param[\"model_path\"] = model_path\n",
    "\n",
    "psp = ProteinStructurePrediction(protein_model, method, config_path, **psp_param)\n",
    "\n",
    "psp.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialization = 'random'\n",
    "method = 'qfold-qc'\n",
    "\n",
    "model_name = \"{}+{}\".format(protein_name, initialization)\n",
    "\n",
    "protein_model = protein_models.get_model(protein_name, method, model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:initial protein structure prediction using qfold-qc in QFold\n",
      "INFO:qiskit.compiler.assembler:Total Assembly Time - 0.10872 (ms)\n",
      "INFO:qiskit.compiler.assembler:Total Assembly Time - 0.05507 (ms)\n",
      "INFO:qiskit.compiler.assembler:Total Assembly Time - 0.04888 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnitarySynthesis - 0.00954 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnrollCustomDefinitions - 28044.69824 (ms)\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Begin BasisTranslator from source basis {('mcx', 4), ('mcu1', 9), ('mcx', 5), ('snapshot', 16), ('cx', 2), ('ccx', 3), ('cu3', 2), ('x', 1), ('h', 1)} to target basis {'cy', 'mcz', 'mcry', 'set_statevector', 'u2', 'ry', 'sdg', 'quantum_channel', 'kraus', 'x', 'cu', 'initialize', 'rz', 'mcx', 'mcy', 'save_state', 'mcphase', 'roerror', 'rzz', 'cx', 'cz', 'ryy', 'r', 'tdg', 'mcu3', 'mcrz', 'unitary', 'save_probs_ket', 'save_statevector', 'h', 'save_probs', 'u3', 'pauli', 'save_expval', 'cu2', 'csx', 'sx', 'z', 'swap', 'mcsx', 'delay', 'rx', 'u1', 'rzx', 'reset', 'mcrx', 'measure', 'rxx', 'save_amplitudes_sq', 's', 'id', 'cu1', 'multiplexer', 'u', 'qerror_loc', 'ccx', 'p', 'save_density_matrix', 'diagonal', 'mcswap', 'sxdg', 'mcr', 'snapshot', 'y', 'barrier', 'cu3', 'mcp', 'cswap', 't', 'mcu2', 'save_amplitudes', 'mcu', 'cp', 'mcu1'}.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation path search completed in 0.000s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation paths composed in 0.102s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation instructions replaced in 0.481s.\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: BasisTranslator - 765.05399 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: RemoveResetInZeroState - 41.34297 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: Depth - 36.91363 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: FixedPoint - 0.01311 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: Optimize1qGatesDecomposition - 38992.56778 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: CXCancellation - 49.39699 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnitarySynthesis - 0.01049 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnrollCustomDefinitions - 85.86240 (ms)\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Begin BasisTranslator from source basis {('mcx', 4), ('u2', 1), ('mcu1', 9), ('mcx', 5), ('snapshot', 16), ('u3', 1), ('ccx', 3), ('cx', 2), ('cu3', 2), ('x', 1), ('h', 1)} to target basis {'cy', 'mcz', 'mcry', 'set_statevector', 'u2', 'ry', 'sdg', 'quantum_channel', 'kraus', 'x', 'cu', 'initialize', 'rz', 'mcx', 'mcy', 'save_state', 'mcphase', 'roerror', 'rzz', 'cx', 'cz', 'ryy', 'r', 'tdg', 'mcu3', 'mcrz', 'unitary', 'save_probs_ket', 'save_statevector', 'h', 'save_probs', 'u3', 'pauli', 'save_expval', 'cu2', 'csx', 'sx', 'z', 'swap', 'mcsx', 'delay', 'rx', 'u1', 'rzx', 'reset', 'mcrx', 'measure', 'rxx', 'save_amplitudes_sq', 's', 'id', 'cu1', 'multiplexer', 'u', 'qerror_loc', 'ccx', 'p', 'save_density_matrix', 'diagonal', 'mcswap', 'sxdg', 'mcr', 'snapshot', 'y', 'barrier', 'cu3', 'mcp', 'cswap', 't', 'mcu2', 'save_amplitudes', 'mcu', 'cp', 'mcu1'}.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation path search completed in 0.000s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation paths composed in 0.047s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation instructions replaced in 0.240s.\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: BasisTranslator - 356.38905 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: Depth - 18.78142 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: FixedPoint - 0.01168 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: Optimize1qGatesDecomposition - 8630.22232 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: CXCancellation - 50.75049 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnitarySynthesis - 0.01955 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnrollCustomDefinitions - 85.43229 (ms)\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Begin BasisTranslator from source basis {('mcx', 4), ('u2', 1), ('mcu1', 9), ('mcx', 5), ('snapshot', 16), ('u3', 1), ('ccx', 3), ('cx', 2), ('cu3', 2), ('x', 1), ('h', 1)} to target basis {'cy', 'mcz', 'mcry', 'set_statevector', 'u2', 'ry', 'sdg', 'quantum_channel', 'kraus', 'x', 'cu', 'initialize', 'rz', 'mcx', 'mcy', 'save_state', 'mcphase', 'roerror', 'rzz', 'cx', 'cz', 'ryy', 'r', 'tdg', 'mcu3', 'mcrz', 'unitary', 'save_probs_ket', 'save_statevector', 'h', 'save_probs', 'u3', 'pauli', 'save_expval', 'cu2', 'csx', 'sx', 'z', 'swap', 'mcsx', 'delay', 'rx', 'u1', 'rzx', 'reset', 'mcrx', 'measure', 'rxx', 'save_amplitudes_sq', 's', 'id', 'cu1', 'multiplexer', 'u', 'qerror_loc', 'ccx', 'p', 'save_density_matrix', 'diagonal', 'mcswap', 'sxdg', 'mcr', 'snapshot', 'y', 'barrier', 'cu3', 'mcp', 'cswap', 't', 'mcu2', 'save_amplitudes', 'mcu', 'cp', 'mcu1'}.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation path search completed in 0.000s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation paths composed in 0.047s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation instructions replaced in 0.239s.\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: BasisTranslator - 354.57277 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: Depth - 19.61136 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: FixedPoint - 0.01192 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: Optimize1qGatesDecomposition - 8640.01012 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: CXCancellation - 49.99757 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnitarySynthesis - 0.01025 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: UnrollCustomDefinitions - 84.86700 (ms)\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Begin BasisTranslator from source basis {('mcx', 4), ('u2', 1), ('mcu1', 9), ('mcx', 5), ('snapshot', 16), ('u3', 1), ('ccx', 3), ('cx', 2), ('cu3', 2), ('x', 1), ('h', 1)} to target basis {'cy', 'mcz', 'mcry', 'set_statevector', 'u2', 'ry', 'sdg', 'quantum_channel', 'kraus', 'x', 'cu', 'initialize', 'rz', 'mcx', 'mcy', 'save_state', 'mcphase', 'roerror', 'rzz', 'cx', 'cz', 'ryy', 'r', 'tdg', 'mcu3', 'mcrz', 'unitary', 'save_probs_ket', 'save_statevector', 'h', 'save_probs', 'u3', 'pauli', 'save_expval', 'cu2', 'csx', 'sx', 'z', 'swap', 'mcsx', 'delay', 'rx', 'u1', 'rzx', 'reset', 'mcrx', 'measure', 'rxx', 'save_amplitudes_sq', 's', 'id', 'cu1', 'multiplexer', 'u', 'qerror_loc', 'ccx', 'p', 'save_density_matrix', 'diagonal', 'mcswap', 'sxdg', 'mcr', 'snapshot', 'y', 'barrier', 'cu3', 'mcp', 'cswap', 't', 'mcu2', 'save_amplitudes', 'mcu', 'cp', 'mcu1'}.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation path search completed in 0.000s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation paths composed in 0.046s.\n",
      "INFO:qiskit.transpiler.passes.basis.basis_translator:Basis translation instructions replaced in 0.235s.\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: BasisTranslator - 351.00746 (ms)\n",
      "INFO:qiskit.transpiler.runningpassmanager:Pass: ContainsInstruction - 0.00811 (ms)\n",
      "INFO:qiskit.compiler.transpiler:Total Transpile Time - 89448.92812 (ms)\n",
      "INFO:qiskit.compiler.assembler:Total Assembly Time - 0.11826 (ms)\n",
      "INFO:qiskit.execute_function:Total Job Submission Time - 394.50932 (ms)\n",
      "INFO:root:QUANTUM METROPOLIS: Time for final steps 95.56904292106628 seconds (91.58702278137207 seconds statevector)\n",
      "INFO:root:finish save tts_results_glycylglycine_3_GG+random_1000_qfold-qc.json\n"
     ]
    }
   ],
   "source": [
    "psp = ProteinStructurePrediction(protein_model, method, config_path, **psp_param)\n",
    "\n",
    "psp.run()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Post Process\n",
    "\n",
    "In this part, we will show how to visualize the results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Job Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from braket.aws import AwsDevice\n",
    "from braket.aws import AwsQuantumJob, AwsSession\n",
    "from braket.jobs.config import InstanceConfig\n",
    "\n",
    "import boto3\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Prepare parameters for batch evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we set the parameters for batch evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters for experiments: \n",
      " [{'method': 'qfold-cc', 'initialization': 'minifold', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'method': 'qfold-cc', 'initialization': 'minifold', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}, {'method': 'qfold-cc', 'initialization': 'random', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'method': 'qfold-cc', 'initialization': 'random', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}, {'method': 'qfold-qc', 'initialization': 'minifold', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'method': 'qfold-qc', 'initialization': 'minifold', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}, {'method': 'qfold-qc', 'initialization': 'random', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.large'}}, {'method': 'qfold-qc', 'initialization': 'random', 'shots': 10000, 'mode': 'local-simulator', 'device': {'qc': 'null', 'cc': 'ml.m5.4xlarge'}}]\n"
     ]
    }
   ],
   "source": [
    "# parameters for experiments\n",
    "experiment_name = \"QfoldHybridJobs\"\n",
    "data_path = \"protein-folding-data\"\n",
    "suffix_check = [\"json\"]\n",
    "experiments_params =  {\n",
    "    \"version\": \"1\",\n",
    "    \"params\": [\n",
    "        {\"method\": [\"qfold-cc\", \"qfold-qc\"]},\n",
    "        {\"initialization\": [\"minifold\", \"random\"]},\n",
    "        {\"shots\": [10000]},\n",
    "        {\"mode\": [\"local-simulator\"]},\n",
    "        {\"device\": [{\"qc\": \"null\", \"cc\": \"ml.m5.large\"},{\"qc\": \"null\", \"cc\": \"ml.m5.4xlarge\"}]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "hp = {}\n",
    "hybrid_job_params = []\n",
    "parse_params(experiments_params['params'], hp, hybrid_job_params)\n",
    "\n",
    "print(f\"parameters for experiments: \\n {hybrid_job_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload data to s3 path: s3://amazon-braket-us-east-1-002224604296/protein-folding-data\n"
     ]
    }
   ],
   "source": [
    "# Upload dataset to S3\n",
    "s3_path = upload_data(data_path)\n",
    "print(f\"upload data to s3 path: {s3_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Prepare image for experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we use the following code to prepare the image for experiment. For the first run, \n",
    "please run build_and_push.sh to create the image. For future experiments, avoid running\n",
    "build_and_push.sh unless you want to rebuild the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /home/ubuntu/psi4conda/bin/psi4 QfoldHybridJobs/psi4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the hybrid job image for 002224604296 in region us-east-1: 002224604296.dkr.ecr.us-east-1.amazonaws.com/amazon-braket-qfoldhybridjobs-jobs:latest\n"
     ]
    }
   ],
   "source": [
    "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = boto3.client('s3').meta.region_name\n",
    "image_name = f\"amazon-braket-{experiment_name.lower()}-jobs\"\n",
    "image_uri = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{image_name}:latest\"\n",
    "\n",
    "print(f\"the hybrid job image for {account_id} in region {region}: {image_uri}\")\n",
    "\n",
    "# For the first run, please use the following code to create the image for this application. For future experiments, comment\n",
    "# the following code unless you want to rebuild the image\n",
    "# !sh build_and_push.sh {image_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job info will be saved in QfoldHybridJobs-hybrid-jobs.json\n"
     ]
    }
   ],
   "source": [
    "hybrid_jobs_json = f\"{experiment_name}-hybrid-jobs.json\"\n",
    "print(f\"job info will be saved in {hybrid_jobs_json}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Launch Amazon Braket Hybrid Jobs for experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we use the following code to launch the same number of hybrid jobs as the sets of parameters for this experiments.\n",
    "When the number of jobs exceeds 5 RPS, this thread will wait. The default setting of this experiment will take around **7 hours** to \n",
    "finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'QfoldHybridJobs-hybrid-jobs.json': No such file or directory\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "name is q-m-l-ml-m5-large-1679454022\n",
      "Finish create QfoldHybridJobs with q-m-l-ml-m5-large-1679454022\n",
      "There are 1 jobs in RUNNING or QUEUED status\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "name is q-m-l-ml-m5-4large-1679454037\n",
      "Finish create QfoldHybridJobs with q-m-l-ml-m5-4large-1679454037\n",
      "There are 2 jobs in RUNNING or QUEUED status\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "name is q-r-l-ml-m5-large-1679454044\n",
      "Finish create QfoldHybridJobs with q-r-l-ml-m5-large-1679454044\n",
      "There are 3 jobs in RUNNING or QUEUED status\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "name is q-r-l-ml-m5-4large-1679454050\n",
      "Finish create QfoldHybridJobs with q-r-l-ml-m5-4large-1679454050\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 3 jobs in RUNNING or QUEUED status\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "name is q-m-l-ml-m5-large-1679454236\n",
      "Finish create QfoldHybridJobs with q-m-l-ml-m5-large-1679454236\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 3 jobs in RUNNING or QUEUED status\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "name is q-m-l-ml-m5-4large-1679454268\n",
      "Finish create QfoldHybridJobs with q-m-l-ml-m5-4large-1679454268\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 3 jobs in RUNNING or QUEUED status\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "name is q-r-l-ml-m5-large-1679454314\n",
      "Finish create QfoldHybridJobs with q-r-l-ml-m5-large-1679454314\n",
      "There are 3 jobs in RUNNING or QUEUED status\n",
      "fail to get null: list index out of range, use sv1 instead\n",
      "name is q-r-l-ml-m5-4large-1679454322\n",
      "Finish create QfoldHybridJobs with q-r-l-ml-m5-4large-1679454322\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 4 jobs in RUNNING or QUEUED status\n",
      "There are 3 jobs in RUNNING or QUEUED status\n",
      "Finish launch all the hybrid jobs and save all the files\n"
     ]
    }
   ],
   "source": [
    "# Long runnning cell due to Burst rate of CreateJob requests < 5 RPS\n",
    "# sudo apt-get install python-prctl at first\n",
    "# https://stackoverflow.com/questions/34361035/python-thread-name-doesnt-show-up-on-ps-or-htop\n",
    "from threading import Thread\n",
    "import threading\n",
    "import setproctitle\n",
    "\n",
    "def launch_hybrid_jobs(hybrid_job_params=hybrid_job_params, hybrid_jobs_json=hybrid_jobs_json):\n",
    "    setproctitle.setproctitle(threading.current_thread().name)\n",
    "    # parse evaluation parameters and trigger hybrid jobs:\n",
    "    jobs = []\n",
    "    names = []\n",
    "\n",
    "    job_name = experiment_name.lower()\n",
    "    device_param_list = [\"shots\", \"device\"]\n",
    "\n",
    "    for job_param in hybrid_job_params:\n",
    "        \n",
    "        algorithm_param_name = \"\"\n",
    "        for k,v in job_param.items():\n",
    "            if k not in device_param_list:\n",
    "                algorithm_param_name = algorithm_param_name+f\"-{v[0]}\"\n",
    "        algorithm_param_name=algorithm_param_name[1:]\n",
    "        quantum_device = get_quantum_device(job_param['device']['qc'])\n",
    "        classical_device = job_param['device']['cc']\n",
    "\n",
    "        device_name = classical_device.replace(\".\",\"-\")\n",
    "        device_name = device_name.replace(\"x\",\"\")\n",
    "        \n",
    "        name = f\"{algorithm_param_name}-{device_name}-\" + str(int(time.time()))\n",
    "        name = name.lower()\n",
    "        # name = f\"{experiment_name}-\"+ str(int(time.time()))\n",
    "        print(f\"name is {name}\")\n",
    "\n",
    "        tmp_job = AwsQuantumJob.create(\n",
    "            device=quantum_device,\n",
    "            source_module=f\"{experiment_name}\",\n",
    "            entry_point=f\"{experiment_name}.{job_name}:main\",\n",
    "            job_name=name,\n",
    "            hyperparameters=job_param,\n",
    "            input_data=s3_path,\n",
    "            instance_config=InstanceConfig(instanceType=classical_device),\n",
    "            image_uri=image_uri,\n",
    "            wait_until_complete=False,\n",
    "        )\n",
    "        \n",
    "#         from braket.jobs.local import LocalQuantumJob\n",
    "        \n",
    "#         tmp_job = LocalQuantumJob.create(\n",
    "#             device=quantum_device,\n",
    "#             source_module=f\"{experiment_name}\",\n",
    "#             entry_point=f\"{experiment_name}.{job_name}:main\",\n",
    "#             hyperparameters=job_param,\n",
    "#             input_data=s3_path,\n",
    "#             image_uri=image_uri,\n",
    "#         )   \n",
    "        \n",
    "        print(f\"Finish create {experiment_name} with {name}\")\n",
    "\n",
    "        jobs.append(tmp_job)\n",
    "        names.append(name)\n",
    "\n",
    "\n",
    "        while not queue_check(jobs):\n",
    "            time.sleep(5)\n",
    "    jobs_arn = []\n",
    "\n",
    "    for job in jobs:\n",
    "        jobs_arn.append(job.arn)\n",
    "\n",
    "    jobs_states = {\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"hybrid-jobs-arn\": jobs_arn,\n",
    "        \"names\": names\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # save hybrid job arn for further analysis\n",
    "    json_object = json.dumps(jobs_states, indent=4)\n",
    "\n",
    "    with open(hybrid_jobs_json, \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "        \n",
    "    print(f\"Finish launch all the hybrid jobs and save all the files\")\n",
    "\n",
    "# remove existing hybrid_jobs_json file\n",
    "!rm {hybrid_jobs_json}\n",
    "\n",
    "t = Thread(target=launch_hybrid_jobs, name=\"launch-hybrid-job\", daemon=True).start()\n",
    "\n",
    "# launch_hybrid_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ubuntu     52285  0.7  1.0 2466724 343908 ?      Ssl  02:42   0:16 launch-hybrid-job\n",
      "ubuntu     53803  0.0  0.0   8756  3432 pts/21   Ss+  03:20   0:00 /bin/bash -c ps -aux | grep launch-hybrid-job\n",
      "ubuntu     53808  0.0  0.0   8176   728 pts/21   S+   03:20   0:00 grep launch-hybrid-job\n"
     ]
    }
   ],
   "source": [
    "# run the following scripts to check the created threads\n",
    "!ps -aux | grep launch-hybrid-job"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Jobs finish and visualize results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please use the following code to check the status of hybrid jobs. The status of hybrid jobs can also be checked in the Amazon Braket console. Optionally, if the email if input when deploying the solution, emails will be sent at the same number of hybrid jobs once \n",
    "the status of jobs changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the state of job q-m-l-ml-m5-large-1679454022 is : COMPLETED\n",
      "the state of job q-m-l-ml-m5-4large-1679454037 is : COMPLETED\n",
      "the state of job q-r-l-ml-m5-large-1679454044 is : COMPLETED\n",
      "the state of job q-r-l-ml-m5-4large-1679454050 is : COMPLETED\n",
      "the state of job q-m-l-ml-m5-large-1679454236 is : COMPLETED\n",
      "the state of job q-m-l-ml-m5-4large-1679454268 is : COMPLETED\n",
      "the state of job q-r-l-ml-m5-large-1679454314 is : COMPLETED\n",
      "the state of job q-r-l-ml-m5-4large-1679454322 is : COMPLETED\n",
      "all jobs completed\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'hypermeter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-23-3e01f4d6d402>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m     23\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     24\u001b[0m         \u001b[0;31m# display results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisplay_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiments_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"JSON file for job arns not generated! please wait for the thread(launch-hybrid-job) to finish\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;32m<ipython-input-13-aa9b9d2db559>\u001b[0m in \u001b[0;36mdisplay_results\u001b[0;34m(results, experiments_params)\u001b[0m\n",
      "\u001b[1;32m    118\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    119\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hypermeter\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m    122\u001b[0m             \u001b[0mdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mKeyError\u001b[0m: 'hypermeter'"
     ]
    }
   ],
   "source": [
    "# run the following code to test whether all the jobs finish\n",
    "results = []\n",
    "if os.path.exists(hybrid_jobs_json):\n",
    "    # recover hybrid jobs and show result\n",
    "    jobs_states_load = None\n",
    "    with open(hybrid_jobs_json, \"r\") as outfile:\n",
    "        jobs_states_load = json.load(outfile)\n",
    "\n",
    "    completed_jobs_arn = set()\n",
    "\n",
    "    for job_name, job_arn in zip(jobs_states_load[\"names\"], jobs_states_load[\"hybrid-jobs-arn\"]):\n",
    "        current_job = AwsQuantumJob(job_arn)\n",
    "        print(f\"the state of job {job_name} is : {current_job.state()}\")\n",
    "        if current_job.state() == 'COMPLETED':\n",
    "            completed_jobs_arn.update({job_arn})\n",
    "\n",
    "    whole_jobs_num = len(jobs_states_load[\"names\"])\n",
    "\n",
    "    if len(completed_jobs_arn) == whole_jobs_num:\n",
    "        print(f\"all jobs completed\")\n",
    "        for job_arn in completed_jobs_arn:\n",
    "            current_job = AwsQuantumJob(job_arn)\n",
    "            results.append(current_job.result())\n",
    "        # display results\n",
    "        results = display_results(results, experiments_params)\n",
    "else:\n",
    "    print(f\"JSON file for job arns not generated! please wait for the thread(launch-hybrid-job) to finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)\n",
      "\u001b[0;32m<ipython-input-11-d520545c3318>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m      3\u001b[0m \u001b[0mx_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      4\u001b[0m \u001b[0my_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\'\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m      7\u001b[0m     \u001b[0mdict_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fail to get null: list index out of range, use sv1 instead\n",
      "name is qfold-cc-minifold-local-simulator-ml-m5-large-1679452955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread launch-hybrid-job:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/qfold-python3.7/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/envs/qfold-python3.7/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-8-13347a113ad7>\", line 44, in launch_hybrid_jobs\n",
      "    wait_until_complete=False,\n",
      "  File \"/opt/conda/envs/qfold-python3.7/lib/python3.7/site-packages/braket/aws/aws_quantum_job.py\", line 198, in create\n",
      "    job_arn = aws_session.create_job(**create_job_kwargs)\n",
      "  File \"/opt/conda/envs/qfold-python3.7/lib/python3.7/site-packages/braket/aws/aws_session.py\", line 244, in create_job\n",
      "    response = self.braket_client.create_job(**boto3_kwargs)\n",
      "  File \"/opt/conda/envs/qfold-python3.7/lib/python3.7/site-packages/botocore/client.py\", line 508, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "  File \"/opt/conda/envs/qfold-python3.7/lib/python3.7/site-packages/botocore/client.py\", line 911, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.exceptions.ClientError: An error occurred (BadRequestException) when calling the CreateJob operation: Invalid request body\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rename_result = {}\n",
    "device_list = []\n",
    "x_list = []\n",
    "y_list = []\n",
    "for k,vs in results.items():\n",
    "    k = k.replace(\"\\'\",\"\\\"\")\n",
    "    dict_k = json.loads(k)\n",
    "    device_name = None\n",
    "    if dict_k['qc'] == 'null':\n",
    "        device_name = dict_k['cc']\n",
    "    else:\n",
    "        device_name = dict_k['qc']\n",
    "    for v in vs:\n",
    "        device_list.append(device_name)\n",
    "        x_list.append(v[0])\n",
    "        y_list.append(v[1])\n",
    "source = pd.DataFrame({\n",
    "    \"Sequence Length\": np.array(x_list),\n",
    "    \"Time to Solution\": np.array(y_list),\n",
    "    \"Device\": np.array(device_list),\n",
    "})\n",
    "\n",
    "alt.Chart(source).mark_line(point = True).encode(\n",
    "    x='Sequence Length',\n",
    "    y='Time to Solution',\n",
    "    color='Device',\n",
    ").properties(\n",
    "    title = f\"{experiment_name} experiments\",\n",
    "    width = 700,\n",
    "    height = 600,\n",
    ").interactive()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
