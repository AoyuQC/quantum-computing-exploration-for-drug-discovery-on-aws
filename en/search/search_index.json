{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"AWS Quantum Ready Solution for Drug Discovery (AWS QRSDD) helps customers study drug discovery problems using quantum computing (Amazon Braket), such as molecular docking and protein folding. Customers can easily leverage this solution to orchestrate workflows that run on both classical and quantum as needed. This solution mainly includes the following features: Launch a hybrid solution architecture with just 1-click Flexibility for customers to use either quantum or classical compute resource or both in HPC architecture Sample codes to show how to use quantum computing, classical computing or both to study the drug discovery problems The analytics data and diagrams are provided in BI service (Amazon QuickSight) to evaluate the experiment values (e.g. cost, performance, time) This implementation guide describes architectural considerations and configuration steps for deploying the quantum ready solution for drug discovery in the Amazon Web Services (AWS) cloud. It includes links to [CloudFormation][cloudformation] templates that launches and configures the AWS services required to deploy this solution using AWS best practices for security and availability. The guide is intended for IT architects, developers, DevOps, data scientists, and algorithm engineers with practical experience architecting in the AWS Cloud.","title":"Welcome"},{"location":"additional-resources/","text":"AWS SageMaker Notebook Amazon Braket AWS Step Function AWS Batch Amazon S3 Amazon EventBridge AWS Lambda Amazon Athena Amazon QuickSight","title":"Additional resources"},{"location":"architecture/","text":"Deploying this solution with the default parameters builds the following environment in the AWS Cloud. Figure 1: The quantum ready solution for drug discovery architecture on AWS This solution deploys the Amazon CloudFormation template in your AWS Cloud account and provides three URLs. One for Visualization . The others provide user with two approaches to study drug discovery problems: Notebook Experiment and Batch Evaluation : The solution deploys an instance for AWS SageMaker Notebook . The user can do Notebook Experiment for drug discovery on classical computing and quantum computing in this notebook. The notebook comes with prepared sample code for different problems in drug discovery, like molecular unfolding, molecule simulation and so on. The user can learn how to study these problems based on classical or quantum computing resource through Amazon Braket . The step-by-step guide is provided in the Workshop Page . The notebook provides the user with the public network access to download necessary software for experiments. The solution also deploys AWS Step Function for user to do Batch Evaluation . The AWS Step Function launches various computing tasks through AWS Batch jobs based on different resources. Instances launched by AWS Batch try to evaluate a particular problem based on different computing resources , classical computing or quantum computing. For example, for the problem of molecular unfolding, the performance difference between quantum annealer and simulated annealer can be compared. The images for Batch Evaluation have been built in Amazon ECR . For customizing the logic for Batch Evaluation , please refer to Batch Evaluate Your Own Model Page . The Batch Evaluation deploys VPC Endpoints to ensure secure connection to AWS services: Amazon ECR, Amazon S3, Amazon Braket. The batch job for testing quantum algorithm submits the quantum computing jobs/tasks through Amazon Braket. Either classical computing task or quantum computing jobs/tasks complete, the results will be saved to Amazon S3 , When quantum computing jobs/tasks complete, Amazon EventBridge triggers the listener AWS Lambda . The listener lambda sends a callback to the step function. When all the steps complete, a notification is send out by Amazon SNS . The Glue table is created by Amazon Athena based on metrics data in Amazon S3. The user can view the Batch Evaluation results(e.g. cost, performance) through Amazon QuickSight","title":"Architecture Overview"},{"location":"benchmark/","text":"Run Benchmark We will run benchmark through AWS StepFunctions workflow and view the result via AWS QuickSight dashboard Get StepFunctions link from deployment output Start Execution All input fields of the input json is optional, but you can customize anything about model parameters, computing rescoures, QC devices, optimizer parameters. The input scheam: { \"version\" : \"string\" , \"runMode\" : \"string\" , \"molFile\" : \"string\" , \"modelVersion\" : \"string\" , \"experimentName\" : \"string\" , \"optParams\" : { \"qa\" : { \"shots\" : \"int\" , \"embed_method\" : \"string\" }, \"sa\" : { \"shots\" : \"int\" , \"notes\" : \"string\" } }, \"modelParams\" : { \"M\" : \"int []\" , \"D\" : \"int []\" , \"A\" : \"int []\" , \"HQ\" : \"int []\" , }, \"devicesArns\" : \"string []\" , \"hpcResources\" : \"[int, int] []\" , } Definition: version : the version of input schema , current only support value is : '1' runModel : ALL | HPC | QC , default : 'ALL' molFile : s3 url of the file modelVersion : any string , default : 'latest' experimentName : any string hpcResources : 2 - d array , e . g : 2 vCPU /4GiB memory and 4 vCPU/ 8 GiB memory : [[ 2 , 4 ], [ 4 , 8 ]] A typical and default(if input json is {} ) input: { \"version\" : \"1\" , \"runMode\" : \"ALL\" , \"optParams\" : { \"qa\" : { \"shots\" : 1000 }, \"sa\" : { \"shots\" : 1000 } }, \"modelParams\" : { \"M\" : [ 1 , 2 , 3 , 4 ], \"D\" : [ 4 ], \"A\" : [ 300 ], \"HQ\" : [ 200 ] }, \"devicesArns\" : [ \"arn:aws:braket:::device/qpu/d-wave/DW_2000Q_6\" , \"arn:aws:braket:::device/qpu/d-wave/Advantage_system4\" ], \"hpcResources\" : [ [ 2 , 2 ], [ 4 , 4 ], [ 8 , 8 ], [ 16 , 16 ] ] } View dashboard Dashbaord link If you run StepFunctions multi-times, by default, the dashbaord average metrics of all executions. You can click a item in the experiment hist table in the left-upper corner to view the result of a specific execution. Trouble shooting StepFunctions failed becasue of \"Check Input\" step failed. If the input json not is passed the input validation, this step fails. Check the errorMessage of the step, fix your input. StepFunctions failed becasue of Lambda.TooManyRequestsException . If you run the StepFunctions with high a frequency, you may get this error, you can wait serveal seconds and retry. Dashboard can not be displayed, the error message complains permission error when accessing data in S3 bucket. Go to quicksight admin , in QuickSight access to AWS services , make sure your S3 bucket is checked.","title":"Benchmark"},{"location":"benchmark/#run-benchmark","text":"We will run benchmark through AWS StepFunctions workflow and view the result via AWS QuickSight dashboard","title":"Run Benchmark"},{"location":"benchmark/#get-stepfunctions-link-from-deployment-output","text":"","title":"Get StepFunctions link from deployment output"},{"location":"benchmark/#start-execution","text":"All input fields of the input json is optional, but you can customize anything about model parameters, computing rescoures, QC devices, optimizer parameters. The input scheam: { \"version\" : \"string\" , \"runMode\" : \"string\" , \"molFile\" : \"string\" , \"modelVersion\" : \"string\" , \"experimentName\" : \"string\" , \"optParams\" : { \"qa\" : { \"shots\" : \"int\" , \"embed_method\" : \"string\" }, \"sa\" : { \"shots\" : \"int\" , \"notes\" : \"string\" } }, \"modelParams\" : { \"M\" : \"int []\" , \"D\" : \"int []\" , \"A\" : \"int []\" , \"HQ\" : \"int []\" , }, \"devicesArns\" : \"string []\" , \"hpcResources\" : \"[int, int] []\" , } Definition: version : the version of input schema , current only support value is : '1' runModel : ALL | HPC | QC , default : 'ALL' molFile : s3 url of the file modelVersion : any string , default : 'latest' experimentName : any string hpcResources : 2 - d array , e . g : 2 vCPU /4GiB memory and 4 vCPU/ 8 GiB memory : [[ 2 , 4 ], [ 4 , 8 ]] A typical and default(if input json is {} ) input: { \"version\" : \"1\" , \"runMode\" : \"ALL\" , \"optParams\" : { \"qa\" : { \"shots\" : 1000 }, \"sa\" : { \"shots\" : 1000 } }, \"modelParams\" : { \"M\" : [ 1 , 2 , 3 , 4 ], \"D\" : [ 4 ], \"A\" : [ 300 ], \"HQ\" : [ 200 ] }, \"devicesArns\" : [ \"arn:aws:braket:::device/qpu/d-wave/DW_2000Q_6\" , \"arn:aws:braket:::device/qpu/d-wave/Advantage_system4\" ], \"hpcResources\" : [ [ 2 , 2 ], [ 4 , 4 ], [ 8 , 8 ], [ 16 , 16 ] ] }","title":"Start Execution"},{"location":"benchmark/#view-dashboard","text":"Dashbaord link If you run StepFunctions multi-times, by default, the dashbaord average metrics of all executions. You can click a item in the experiment hist table in the left-upper corner to view the result of a specific execution.","title":"View dashboard"},{"location":"benchmark/#trouble-shooting","text":"StepFunctions failed becasue of \"Check Input\" step failed. If the input json not is passed the input validation, this step fails. Check the errorMessage of the step, fix your input. StepFunctions failed becasue of Lambda.TooManyRequestsException . If you run the StepFunctions with high a frequency, you may get this error, you can wait serveal seconds and retry. Dashboard can not be displayed, the error message complains permission error when accessing data in S3 bucket. Go to quicksight admin , in QuickSight access to AWS services , make sure your S3 bucket is checked.","title":"Trouble shooting"},{"location":"cost/","text":"You are responsible for the cost of Amazon cloud technology services used when running this solution. As of January 2022, the estimated cost for the solution is 25.12 USD per day. The whole cost consists of five types: Notebook Compute Storage Analysis Orchestration The actual cost depends on the tasks performed and the complexity. Take the molecular unfolding function for the prepared sample (117_idel.mol2) as an example. The following calculation is based on that customers use the notebook to study sample code as well as use the solution to run one complete batch test both on quantum computing resource and classical computing resource in order to visualize the results in Amazon QuickSight. If the customers only used solution to study the sample code, the cost for notebook and the compute from Amazon Braket were considered. Cost Type Service Resource Size Operating Condition Cost Notebook Amazon Sagemaker Notebook ml.c5.xlarge long run instance 4.90 USD/Day Compute Amazon Braket D-Wave - DW_2000Q_6 4 tasks for different parameters, 10000 shots/task 8.8 USD Amazon Braket D-Wave - Advantage_system4.1 4 tasks for different parameters, 10000 shots/task 8.8 USD Amazon Batch (Fargate) 2 VCPU 4G MEM Tasks like creating models, 8 minutes( < 20 minutes) 1.02 USD Amazon Batch (EC2) 2 VCPU 2G MEM 4 tasks for different parameters, 19 minutes( < 60 minutes) 0.09 USD Amazon Batch (EC2) 4 VCPU 4G MEM 4 tasks for different parameters, 19 minutes( < 60 minutes) 0.17 USD Amazon Batch (EC2) 8 VCPU 8G MEM 4 tasks for different parameters, 19 minutes( < 60 minutes) 0.34 USD Amazon Batch (EC2) 16 VCPU 16G MEM 4 tasks for different parameters, 19 minutes( < 60 minutes) 0.68 USD AWS Lambda - < 100 queries 0 USD Storage Amazon S3 - < 1G 0.02 USD Analysis Amazon Athena - < 20 queries, 100M data 0.029 USD Amazon QuickSight 1 reader long run service 8.00 USD/Month Orchestration AWS Step Functions - < 100 transitions 0 USD Total Cost 25.12 USD/Day","title":"Cost"},{"location":"deployment/","text":"Before you launch the solution, review the architecture, supported regions, and other considerations discussed in this guide. Follow the step-by-step instructions in this section to configure and deploy the solution into your account. Time to deploy : Approximately 10 minutes Deployment overview Use the following steps to deploy this solution on AWS. Check your QuickSight account Launch the AWS CloudFormation template into your AWS account to deploy the solution. Update QuickSight permissions Deployment Check your QuickSight Sign in to the AWS Management Console, navigate to QuickSight If you did not have a QuickSight account, you need to sign up for QuickSight. Choose Enterprise , click continue In the Create your QuickSight account page, fill the necessary information: Go to quicksight admin , record your QuickSight Username (not QuickSight account name). Deploy solution This automated AWS CloudFormation template deploys the solution in the AWS Cloud. Use Launch solution in AWS Standard Regions to launch the AWS CloudFormation template. The template launches in the US West 2 (Oregon) Region by default. To launch this solution in a different AWS Region, use the Region selector in the console navigation bar. On the Create stack page, verify that the correct quantum-ready-solution-for-drug-discovery.template is shown in the Amazon S3 URL text box and choose Next . Under Parameters , review the parameters for the template and modify them as necessary. This solution uses the following values. Choose Next . Parameter Description MolUnfDashboardquickSightUser Quicksight Username On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box acknowledging that the template will create AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation Console in the Status column. You should receive a CREATE_COMPLETE status in approximately 10 minutes. Update QuickSight permissions Navigate to Quicksight admin page Click Manage Click Select S3 Buckets Check the bucket amazon-braket-qcstack-<AWS account>-<region> Click Finish and then Save","title":"Automated Deployment"},{"location":"deployment/#deployment-overview","text":"Use the following steps to deploy this solution on AWS. Check your QuickSight account Launch the AWS CloudFormation template into your AWS account to deploy the solution. Update QuickSight permissions","title":"Deployment overview"},{"location":"deployment/#deployment","text":"","title":"Deployment"},{"location":"deployment/#check-your-quicksight","text":"Sign in to the AWS Management Console, navigate to QuickSight If you did not have a QuickSight account, you need to sign up for QuickSight. Choose Enterprise , click continue In the Create your QuickSight account page, fill the necessary information: Go to quicksight admin , record your QuickSight Username (not QuickSight account name).","title":"Check your QuickSight"},{"location":"deployment/#deploy-solution","text":"This automated AWS CloudFormation template deploys the solution in the AWS Cloud. Use Launch solution in AWS Standard Regions to launch the AWS CloudFormation template. The template launches in the US West 2 (Oregon) Region by default. To launch this solution in a different AWS Region, use the Region selector in the console navigation bar. On the Create stack page, verify that the correct quantum-ready-solution-for-drug-discovery.template is shown in the Amazon S3 URL text box and choose Next . Under Parameters , review the parameters for the template and modify them as necessary. This solution uses the following values. Choose Next . Parameter Description MolUnfDashboardquickSightUser Quicksight Username On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box acknowledging that the template will create AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation Console in the Status column. You should receive a CREATE_COMPLETE status in approximately 10 minutes.","title":"Deploy solution"},{"location":"deployment/#update-quicksight-permissions","text":"Navigate to Quicksight admin page Click Manage Click Select S3 Buckets Check the bucket amazon-braket-qcstack-<AWS account>-<region> Click Finish and then Save","title":"Update QuickSight permissions"},{"location":"faq/","text":"The following are common issues you may face in deploying and using the solution. Deployment 1. In which AWS Regions can this solution be deployed? Please refer to Region Support . 2. When creating a transfer task, shall I deploy it on the data source side or the destination side? The transfer performance of the solution will not be affected by whether the deployment is on the data source or destination side. If you do not have a domain name registered by ICP in AWS China Regions, we recommend you deploy it in AWS Standard Regions. If you need to deploy in AWS China Regions but do not have a domain name, you can directly deploy the back-end version: Amazon S3 Plugin: https://github.com/awslabs/amazon-s3-data-replication-hub-plugin Amazon ECR Plugin: https://github.com/awslabs/amazon-ecr-data-replication-hub-plugin 3. Do I need to deploy the solution on the data source and destination side separately? No. You can choose to deploy on the data source or destination side, which has no impact on the transfer performance. 4. Is it possible to deploy the solution in AWS account A and transfer Amazon S3 objects from account B to account C? Yes. In this case, you need to store the AccessKeyID and SecretAccessKey of account B and account C in the Secrets Manager of account A. 5. For data transfer within the production account, is it recommended to create an AWS account specifically for deploying the solution? Yes. It is recommended to create a new AWS account dedicated to deploying solutions. The account-level isolation improves the stability of the production account in the data synchronization process. 6. Is it possible to transfer data between different areas under the same account? Not supported currently. For this scenario, we recommend using Amazon S3's Cross-Region Replication . Performance 1. Will there be any difference in data transfer performance for deployment in AWS China Regions and in AWS Standard Regions? No. If you do not have a domain name registered by ICP in AWS China Regions, it is recommended to deploy it in the AWS Standard Regions. 2. What are the factors influencing the data transfer performance? The transfer performance may be affected by average file size, destination of data transfer, geographic location of data source, and real-time network environment. For example, using the same configuration, the transfer speed with an average file size of 50MB is 170 times the transfer speed with an average file size of 10KB. Data security and authentication 1. How does the solution ensure data security? The solution adopts the following to ensure data security: All data is transferred in the memory in the transfer node cluster, without being placed on the disk. The external ports of all transfer nodes are closed, and there is no way to SSH into the transfer node. All data download and upload bottom layers are calling AWS official API, and data transfer conforms to the TLS protocol . 2. How does the solution ensure the security of resources on the cloud? In the research and development process, we strictly follow the minimum IAM permission design rules, and adopt the design of Auto Scaling, which will automatically help users terminate idle working nodes. 3. Is the front-end console open to the public network? How to ensure user authentication and multi-user management? Yes. You can access it with a front-end console link. User authentication and multi-user management are achieved through AWS Cognito User Pool in AWS Standard Regions, and through OIDC SAAS in AWS China Regions. 4. How does the solution achieve cross-account and cross-cloud authentication? By authentication through the Access Keyid and Access Key of the other party\u2019s account. The secret key is stored in AWS Secrets Manager and will be read in Secrets Manager as needed. 5. Does the solution support SSE-S3, SSE-KMS, and SSE-CMK? Yes. The solution supports the use of SSE-S3 and SSE-KMS data sources. If your source bucket has SSE-CMK enabled, please refer to Tutorial . Features 1. What third-party clouds does Amazon S3 sync currently support? Alibaba Cloud OSS, Tencent Cloud, Huawei Cloud, Qiniu Cloud, Baidu Cloud, and all clouds that support S3 compatible protocols. 2. Why is the status of Task still in progress after all destination files are transferred? When will the task stop? The data difference between the data source and destination will be monitored continuously, and the differences between the two sides will be automatically compared after the first deployment. Moreover, when the default comparison task once an hour finds a difference, it will also transfer the difference data. Therefore, the status of the Task will always be in progress, unless the user manually terminates the task. Based on the built-in automatic expansion function of the solution, when there is no data to be transferred, the number of transfer working nodes will be automatically reduced to the minimum value configured by the user. 3. How often will the data difference between the data source and destination be compared\uff1f By default, it runs hourly. At Task Scheduling Settings , you can make the task scheduling configuration. If you want to configure the timed task at a fixed frequency to compare the data difference on both sides of the time, select Fixed Rate . If you want to configure a scheduled task through Cron Expression to achieve a scheduled comparison of data differences on both sides, select CroExpression . If you only want to perform the data synchronization task once, select One Time Transfer . 4. Is it possible for real-time synchronization of newly added files? Near-real-time synchronization can be achieved, only if the Data Transfer Hub is deployed in the same AWS account and the same region as the data source. If the data source and the solution are not in the same account, you can configure it manually. For more information, refer to Tutorial . 5. Are there restrictions on the number of files and the size of files? No. Larger files will be uploaded in chunks. 6. If a single file transfer fails due to network issues, how to resolve it? Is there an error handling mechanism? There will be 5 retries. After 5 retries without success, the task will be notified to the user via email. 7. How to monitor the progress of the transfer by checking information like how many files are waiting to be transferred and the current transfer speed? You can jump to the customized dashboard of Amazon CloudWatch by clicking the CloudWatch Dashboard link in Task Detail of the web console. You can also go directly to CloudWatch to view it. Others 1. I get a 403 GetObject Access Denied error. How to resolve it? Please check whether the Credential stored in Secrets Manager has the proper permissions. For more information, refer to IAM Policy . 2. The cluster node (EC2) is terminated by mistake. How to resolve it? The Auto Scaling mechanism of the solution will enable automatic restart of a new working node. However, if a sharding task being transferred in the node is mistakenly terminated, it may cause that the files to which the shard belongs cannot be merged on the destination side, and the error \"api error NoSuchUpload: The specified upload does not exist. The upload ID may be invalid, or the upload may have been aborted or completed\" occurs. You need to configure lifecycle rules for Delete expired delete markers or incomplete multipart uploads in the Amazon S3 bucket. 3. The Secrets configuration in Secrets Manager is wrong. How to resolve it? Please update Secrets in Secrets Manager first, and then go to the EC2 console to Terminate all EC2 instances that have been started by the task. Later, the Auto Scaling mechanism of the solution will automatically start a new working node and update Secrets to it. 4. How to find detailed transfer log? When deploying the stack, you will be asked to enter the stack name ( DTHS3Stack by default), and most resources will be created with the name prefix as the stack name. For example, the format of the queue name is <StackName>-S3TransferQueue-<random suffix> . This plugin will create two main log groups. If there is no data transfer, you need to check whether there is a problem in the ECS task log. The following is the log group for scheduling ECS tasks. <StackName>-ECSStackFinderLogGroup<random suffix> The following are the log groups of all EC2 instances, and you can find detailed transfer logs. <StackName>-EC2WorkerStackS3RepWorkerLogGroup\\<random suffix> 5. How to make customized build? If you want to make customized changes to this plugin, please refer to Custom Build . 6. After the deployment is complete, why can't I find any log streams in the two CloudWatch log groups? This is because the subnet you selected when deploying this solution does not have public network access, so the Fargate task cannot pull the image, and EC2 cannot download the CloudWatch agent to send logs to CloudWatch. Please check your VPC settings. After resolving the issue, you need to manually terminate the running EC2 instance (if any) through this solution. Subsequently, the elastic scaling group will automatically start a new instance.","title":"Faq"},{"location":"faq/#deployment","text":"1. In which AWS Regions can this solution be deployed? Please refer to Region Support . 2. When creating a transfer task, shall I deploy it on the data source side or the destination side? The transfer performance of the solution will not be affected by whether the deployment is on the data source or destination side. If you do not have a domain name registered by ICP in AWS China Regions, we recommend you deploy it in AWS Standard Regions. If you need to deploy in AWS China Regions but do not have a domain name, you can directly deploy the back-end version: Amazon S3 Plugin: https://github.com/awslabs/amazon-s3-data-replication-hub-plugin Amazon ECR Plugin: https://github.com/awslabs/amazon-ecr-data-replication-hub-plugin 3. Do I need to deploy the solution on the data source and destination side separately? No. You can choose to deploy on the data source or destination side, which has no impact on the transfer performance. 4. Is it possible to deploy the solution in AWS account A and transfer Amazon S3 objects from account B to account C? Yes. In this case, you need to store the AccessKeyID and SecretAccessKey of account B and account C in the Secrets Manager of account A. 5. For data transfer within the production account, is it recommended to create an AWS account specifically for deploying the solution? Yes. It is recommended to create a new AWS account dedicated to deploying solutions. The account-level isolation improves the stability of the production account in the data synchronization process. 6. Is it possible to transfer data between different areas under the same account? Not supported currently. For this scenario, we recommend using Amazon S3's Cross-Region Replication .","title":"Deployment"},{"location":"faq/#performance","text":"1. Will there be any difference in data transfer performance for deployment in AWS China Regions and in AWS Standard Regions? No. If you do not have a domain name registered by ICP in AWS China Regions, it is recommended to deploy it in the AWS Standard Regions. 2. What are the factors influencing the data transfer performance? The transfer performance may be affected by average file size, destination of data transfer, geographic location of data source, and real-time network environment. For example, using the same configuration, the transfer speed with an average file size of 50MB is 170 times the transfer speed with an average file size of 10KB.","title":"Performance"},{"location":"faq/#data-security-and-authentication","text":"1. How does the solution ensure data security? The solution adopts the following to ensure data security: All data is transferred in the memory in the transfer node cluster, without being placed on the disk. The external ports of all transfer nodes are closed, and there is no way to SSH into the transfer node. All data download and upload bottom layers are calling AWS official API, and data transfer conforms to the TLS protocol . 2. How does the solution ensure the security of resources on the cloud? In the research and development process, we strictly follow the minimum IAM permission design rules, and adopt the design of Auto Scaling, which will automatically help users terminate idle working nodes. 3. Is the front-end console open to the public network? How to ensure user authentication and multi-user management? Yes. You can access it with a front-end console link. User authentication and multi-user management are achieved through AWS Cognito User Pool in AWS Standard Regions, and through OIDC SAAS in AWS China Regions. 4. How does the solution achieve cross-account and cross-cloud authentication? By authentication through the Access Keyid and Access Key of the other party\u2019s account. The secret key is stored in AWS Secrets Manager and will be read in Secrets Manager as needed. 5. Does the solution support SSE-S3, SSE-KMS, and SSE-CMK? Yes. The solution supports the use of SSE-S3 and SSE-KMS data sources. If your source bucket has SSE-CMK enabled, please refer to Tutorial .","title":"Data security and authentication"},{"location":"faq/#features","text":"1. What third-party clouds does Amazon S3 sync currently support? Alibaba Cloud OSS, Tencent Cloud, Huawei Cloud, Qiniu Cloud, Baidu Cloud, and all clouds that support S3 compatible protocols. 2. Why is the status of Task still in progress after all destination files are transferred? When will the task stop? The data difference between the data source and destination will be monitored continuously, and the differences between the two sides will be automatically compared after the first deployment. Moreover, when the default comparison task once an hour finds a difference, it will also transfer the difference data. Therefore, the status of the Task will always be in progress, unless the user manually terminates the task. Based on the built-in automatic expansion function of the solution, when there is no data to be transferred, the number of transfer working nodes will be automatically reduced to the minimum value configured by the user. 3. How often will the data difference between the data source and destination be compared\uff1f By default, it runs hourly. At Task Scheduling Settings , you can make the task scheduling configuration. If you want to configure the timed task at a fixed frequency to compare the data difference on both sides of the time, select Fixed Rate . If you want to configure a scheduled task through Cron Expression to achieve a scheduled comparison of data differences on both sides, select CroExpression . If you only want to perform the data synchronization task once, select One Time Transfer . 4. Is it possible for real-time synchronization of newly added files? Near-real-time synchronization can be achieved, only if the Data Transfer Hub is deployed in the same AWS account and the same region as the data source. If the data source and the solution are not in the same account, you can configure it manually. For more information, refer to Tutorial . 5. Are there restrictions on the number of files and the size of files? No. Larger files will be uploaded in chunks. 6. If a single file transfer fails due to network issues, how to resolve it? Is there an error handling mechanism? There will be 5 retries. After 5 retries without success, the task will be notified to the user via email. 7. How to monitor the progress of the transfer by checking information like how many files are waiting to be transferred and the current transfer speed? You can jump to the customized dashboard of Amazon CloudWatch by clicking the CloudWatch Dashboard link in Task Detail of the web console. You can also go directly to CloudWatch to view it.","title":"Features"},{"location":"faq/#others","text":"1. I get a 403 GetObject Access Denied error. How to resolve it? Please check whether the Credential stored in Secrets Manager has the proper permissions. For more information, refer to IAM Policy . 2. The cluster node (EC2) is terminated by mistake. How to resolve it? The Auto Scaling mechanism of the solution will enable automatic restart of a new working node. However, if a sharding task being transferred in the node is mistakenly terminated, it may cause that the files to which the shard belongs cannot be merged on the destination side, and the error \"api error NoSuchUpload: The specified upload does not exist. The upload ID may be invalid, or the upload may have been aborted or completed\" occurs. You need to configure lifecycle rules for Delete expired delete markers or incomplete multipart uploads in the Amazon S3 bucket. 3. The Secrets configuration in Secrets Manager is wrong. How to resolve it? Please update Secrets in Secrets Manager first, and then go to the EC2 console to Terminate all EC2 instances that have been started by the task. Later, the Auto Scaling mechanism of the solution will automatically start a new working node and update Secrets to it. 4. How to find detailed transfer log? When deploying the stack, you will be asked to enter the stack name ( DTHS3Stack by default), and most resources will be created with the name prefix as the stack name. For example, the format of the queue name is <StackName>-S3TransferQueue-<random suffix> . This plugin will create two main log groups. If there is no data transfer, you need to check whether there is a problem in the ECS task log. The following is the log group for scheduling ECS tasks. <StackName>-ECSStackFinderLogGroup<random suffix> The following are the log groups of all EC2 instances, and you can find detailed transfer logs. <StackName>-EC2WorkerStackS3RepWorkerLogGroup\\<random suffix> 5. How to make customized build? If you want to make customized changes to this plugin, please refer to Custom Build . 6. After the deployment is complete, why can't I find any log streams in the two CloudWatch log groups? This is because the subnet you selected when deploying this solution does not have public network access, so the Fargate task cannot pull the image, and EC2 cannot download the CloudWatch agent to send logs to CloudWatch. Please check your VPC settings. After resolving the issue, you need to manually terminate the running EC2 instance (if any) through this solution. Subsequently, the elastic scaling group will automatically start a new instance.","title":"Others"},{"location":"notebook/","text":"Experiment in notebook This solution will deploy a Sagemaker notebook instance with AWS Braket SDK installed and some ready-to-run notebooks of quantum algorithms for drug discovery. Get Notebook link from deployment output open the Notebook link navigate to notebook: src/molecule-unfolding/molecule_unfolding.ipynb you will see the notebook Experiment in notebook see Experiment in notebook","title":"Notebook"},{"location":"notebook/#experiment-in-notebook","text":"This solution will deploy a Sagemaker notebook instance with AWS Braket SDK installed and some ready-to-run notebooks of quantum algorithms for drug discovery.","title":"Experiment in notebook"},{"location":"notebook/#get-notebook-link-from-deployment-output","text":"open the Notebook link navigate to notebook: src/molecule-unfolding/molecule_unfolding.ipynb you will see the notebook","title":"Get Notebook link from deployment output"},{"location":"notebook/#experiment-in-notebook_1","text":"see Experiment in notebook","title":"Experiment in notebook"},{"location":"notices/","text":"Customers are responsible for making their own independent assessment of the information in this document. This document: (a) is for informational purposes only, (b) represents Amazon Web Services current product offerings and practices, which are subject to change without notice, and (c) does not create any commitments or assurances from Amazon Web Services and its affiliates, suppliers or licensors. Amazon Web Services products or services are provided \u201cas is\u201d without warranties, representations, or conditions of any kind, whether express or implied. Amazon Web Services responsibilities and liabilities to its customers are controlled by Amazon Web Services agreements, and this document is not part of, nor does it modify, any agreement between Amazon Web Services and its customers. The AI Video Super Resolution solution is licensed under the terms of the Apache License Version 2.0 available at The Apache Software Foundation .","title":"Notices"},{"location":"regions/","text":"This solution uses services which may not be currently available in all AWS Regions. Launch this solution in an AWS Region where required services are available. For the most current availability by Region, refer to the AWS Regional Services List. As of March 2022, this solution is supported in the following Amazon Web Services Regions: Supported regions for deployment in AWS Standard Regions Region Name Region ID US East (N. Virginia) us-east-1 US West (Oregon) us-west-2","title":"Supported regions"},{"location":"regions/#supported-regions-for-deployment-in-aws-standard-regions","text":"Region Name Region ID US East (N. Virginia) us-east-1 US West (Oregon) us-west-2","title":"Supported regions for deployment in AWS Standard Regions"},{"location":"revisions/","text":"Date Change [March] 2022 Intitial release","title":"Revisions"},{"location":"security/","text":"When you build systems on AWS infrastructure, security responsibilities are shared between you and AWS. This shared model reduces your operational burden because AWS operates, manages, and controls the components including the host operating system, the virtualization layer, and the physical security of the facilities in which the services operate. For more information about AWS security, visit AWS Cloud Security . Security best practices AWS QRSDD is designed with security best practices in mind. However, the security of a solution differs based on your specific use case, and sometimes adding additional security measures will add to the cost of the solution. Th following are additional recommendations to enhance the security posture of AWS QRSDD in production environments. IAM roles AWS Identity and Access Management (IAM) roles allow customers to assign granular access policies and permissions to services and users on the AWS Cloud. This solution creates IAM roles that grant the solution\u2019s access between the solution components. Security groups The security groups created in this solution are designed to control and isolate network traffic between the solution components. We recommend that you review the security groups and further restrict access as needed once the deployment is up and running. Data protection For data protection purposes, we recommend that you protect AWS account credentials and set up individual user accounts with AWS Identity and Access Management (IAM). That way, each user is given only the permissions necessary to fulfill their job duties. We also recommend that you secure your data in the following ways: Use multi-factor authentication (MFA) with each account. Use SSL/TLS to communicate with AWS resources. We recommend TLS 1.2 or later. Set up API and user activity logging with AWS CloudTrail. Use AWS encryption solutions, along with all default security controls within AWS services. Use advanced managed security services such as Amazon Macie, which assists in discovering and securing personal data that is stored in Amazon S3. If you require FIPS 140-2 validated cryptographic modules when accessing AWS through a command line interface or an API, use a FIPS endpoint. For more information about the available FIPS endpoints, see Federal Information Processing Standard (FIPS) 140-2. Data retention After 90 days, Amazon Braket automatically removes all task IDs and other metadata associated with your tasks. As a result of this data retention policy, these tasks and results are no longer retrievable by search from the Amazon Braket console, although they remain stored in your S3 bucket. If you need access to historical tasks and results that are stored in your S3 bucket for longer than 90 days, you must keep a separate record of your task ID and other metadata associated with that data. Be sure to save the information prior to 90 days. You can use that saved information to retrieve the historical data.","title":"Security"},{"location":"security/#security-best-practices","text":"AWS QRSDD is designed with security best practices in mind. However, the security of a solution differs based on your specific use case, and sometimes adding additional security measures will add to the cost of the solution. Th following are additional recommendations to enhance the security posture of AWS QRSDD in production environments.","title":"Security best practices"},{"location":"security/#iam-roles","text":"AWS Identity and Access Management (IAM) roles allow customers to assign granular access policies and permissions to services and users on the AWS Cloud. This solution creates IAM roles that grant the solution\u2019s access between the solution components.","title":"IAM roles"},{"location":"security/#security-groups","text":"The security groups created in this solution are designed to control and isolate network traffic between the solution components. We recommend that you review the security groups and further restrict access as needed once the deployment is up and running.","title":"Security groups"},{"location":"security/#data-protection","text":"For data protection purposes, we recommend that you protect AWS account credentials and set up individual user accounts with AWS Identity and Access Management (IAM). That way, each user is given only the permissions necessary to fulfill their job duties. We also recommend that you secure your data in the following ways: Use multi-factor authentication (MFA) with each account. Use SSL/TLS to communicate with AWS resources. We recommend TLS 1.2 or later. Set up API and user activity logging with AWS CloudTrail. Use AWS encryption solutions, along with all default security controls within AWS services. Use advanced managed security services such as Amazon Macie, which assists in discovering and securing personal data that is stored in Amazon S3. If you require FIPS 140-2 validated cryptographic modules when accessing AWS through a command line interface or an API, use a FIPS endpoint. For more information about the available FIPS endpoints, see Federal Information Processing Standard (FIPS) 140-2.","title":"Data protection"},{"location":"security/#data-retention","text":"After 90 days, Amazon Braket automatically removes all task IDs and other metadata associated with your tasks. As a result of this data retention policy, these tasks and results are no longer retrievable by search from the Amazon Braket console, although they remain stored in your S3 bucket. If you need access to historical tasks and results that are stored in your S3 bucket for longer than 90 days, you must keep a separate record of your task ID and other metadata associated with that data. Be sure to save the information prior to 90 days. You can use that saved information to retrieve the historical data.","title":"Data retention"},{"location":"source/","text":"Visit our GitHub repository to download the templates and scripts for this solution. The AWS QRSDD template is generated using the AWS Cloud Development Kit (CDK) . Refer to the README.md file for additional information.","title":"Source code"},{"location":"template/","text":"To automate deployment, this solution uses the following AWS CloudFormation templates, which you can download before deployment: quantum-ready-solution-for-drug-discovery.template (to be added!): Use this template to launch the solution and all associated components. The default configuration deploys AWS SageMaker Notebook , Amazon Braket , AWS Step Function , AWS Batch , Amazon EventBridge , AWS Lambda ,: Amazon Athena and Amazon QuickSight , but you can customize the template to meet your specific needs.","title":"AWS CloudFormation template"},{"location":"uninstall/","text":"To uninstall the AWS QRSDD solution, you must delete the AWS CloudFormation stack. You can use either the AWS Management Console or the AWS Command Line Interface (AWS CLI) to delete the CloudFormation stack. Uninstall the stack using the AWS Management Console Sign in to the AWS CloudFormation console. Select this solution\u2019s installation parent stack. Choose Delete . Uninstall the stack using AWS Command Line Interface Determine whether the AWS Command Line Interface (AWS CLI) is available in your environment. For installation instructions, refer to What Is the AWS Command Line Interface in the AWS CLI User Guide . After confirming that the AWS CLI is available, run the following command. aws cloudformation delete-stack --stack-name <installation-stack-name> --region <aws-region>","title":"Uninstall the solution"},{"location":"uninstall/#uninstall-the-stack-using-the-aws-management-console","text":"Sign in to the AWS CloudFormation console. Select this solution\u2019s installation parent stack. Choose Delete .","title":"Uninstall the stack using the AWS Management Console"},{"location":"uninstall/#uninstall-the-stack-using-aws-command-line-interface","text":"Determine whether the AWS Command Line Interface (AWS CLI) is available in your environment. For installation instructions, refer to What Is the AWS Command Line Interface in the AWS CLI User Guide . After confirming that the AWS CLI is available, run the following command. aws cloudformation delete-stack --stack-name <installation-stack-name> --region <aws-region>","title":"Uninstall the stack using AWS Command Line Interface"},{"location":"workshop/background/","text":"Quantum Computing For Drug Discovery Solution Quantum Computing For Drug Discovery Solution is a cloud-native solution for the application of quantum computing technology for drug discovery. This solution is trying to bridge the gap between the industrial knowledge and the novel computation model provided by the quantum technologies. This solution will continually implement the Proof of Concepts (PoC) based on the recent publications or reports. It is suitable for customers with needs to evaluate the possible useful cases of quantum computing in their industries. No matter you just start to consider this new technology or on the way, you can use this solution to speed up the process, save time and cost. It is an open-source projects, anyone can contribute to features of adding more related solutions. Biology is one of the science categories that will be directly impacted by quantum. This technology will impact industry verticals such as drug discovery, genetic engineering. Quantum computers represent a paradigm shift in computation. We are entering a fascinating period in the development of quantum computers. As this technology is still in such an early phase, it may be that its true impact is not even fully understood yet. This makes this field even more fascinating to follow. Drug discovery is a high-risk and time-consuming field. The average R&D cost required to bring a new, FDA approved medicine to patients is estimated to be $2.6 billion over the past decade (in 2013 dollars). This includes the cost of the many potential medicines that do not make it through to FDA approval. For example, in research for treatments for Alzheimer\u2019s disease over the past 16 years, for example, only four new medicines have been approved for Alzheimer\u2019s out of 123 treatment attempts that were tested in clinical studies. That\u2019s a 3 percent approval rate. This is also high-reward field., where a blockbuster therapy can deliver life-changing clinical benefits to millions of patients and generate billions of dollars in profit. Let's consider the case for Alzheimer's treatment. The new treatments approved by 2025 that delay the onset of Alzheimer\u2019s by five years would reduce the number of people with the disease by approximately 40 percent and cost for care of patients by $367 billion a year by 2050. Innovation and advancements in computer-aided drug design (CADD) helps increase the productivity in drug research and development. Breakthroughs in artificial intelligence (AI) still rely on statistical models running on classical computers. These devices are limited in modelling quantum mechanical systems such as protein structures. However, hopes for a literal quantum leap in research productivity lie in the development of quantum computers. Researchers have listed the quantum techniques that can be applied to the components in the general workflow of drug discovery process. As the above image shown, both the structured-based methods and ligand-based methods can be beneficial from the techniques in noisy intermediate scale quantum (NISQ) devices and fault-tolerant quantum computing devices.","title":"Overview"},{"location":"workshop/background/#quantum-computing-for-drug-discovery-solution","text":"Quantum Computing For Drug Discovery Solution is a cloud-native solution for the application of quantum computing technology for drug discovery. This solution is trying to bridge the gap between the industrial knowledge and the novel computation model provided by the quantum technologies. This solution will continually implement the Proof of Concepts (PoC) based on the recent publications or reports. It is suitable for customers with needs to evaluate the possible useful cases of quantum computing in their industries. No matter you just start to consider this new technology or on the way, you can use this solution to speed up the process, save time and cost. It is an open-source projects, anyone can contribute to features of adding more related solutions. Biology is one of the science categories that will be directly impacted by quantum. This technology will impact industry verticals such as drug discovery, genetic engineering. Quantum computers represent a paradigm shift in computation. We are entering a fascinating period in the development of quantum computers. As this technology is still in such an early phase, it may be that its true impact is not even fully understood yet. This makes this field even more fascinating to follow. Drug discovery is a high-risk and time-consuming field. The average R&D cost required to bring a new, FDA approved medicine to patients is estimated to be $2.6 billion over the past decade (in 2013 dollars). This includes the cost of the many potential medicines that do not make it through to FDA approval. For example, in research for treatments for Alzheimer\u2019s disease over the past 16 years, for example, only four new medicines have been approved for Alzheimer\u2019s out of 123 treatment attempts that were tested in clinical studies. That\u2019s a 3 percent approval rate. This is also high-reward field., where a blockbuster therapy can deliver life-changing clinical benefits to millions of patients and generate billions of dollars in profit. Let's consider the case for Alzheimer's treatment. The new treatments approved by 2025 that delay the onset of Alzheimer\u2019s by five years would reduce the number of people with the disease by approximately 40 percent and cost for care of patients by $367 billion a year by 2050. Innovation and advancements in computer-aided drug design (CADD) helps increase the productivity in drug research and development. Breakthroughs in artificial intelligence (AI) still rely on statistical models running on classical computers. These devices are limited in modelling quantum mechanical systems such as protein structures. However, hopes for a literal quantum leap in research productivity lie in the development of quantum computers. Researchers have listed the quantum techniques that can be applied to the components in the general workflow of drug discovery process. As the above image shown, both the structured-based methods and ligand-based methods can be beneficial from the techniques in noisy intermediate scale quantum (NISQ) devices and fault-tolerant quantum computing devices.","title":"Quantum Computing For Drug Discovery Solution"},{"location":"workshop/a-molecule-unfolding/batch-test/","text":"Run Batch Test We will run batch test through AWS Step Functions workflow and view the result via AWS QuickSight dashboard Get Step Functions link from deployment output Start Execution All input fields of the input json is optional, but you can customize anything about model parameters, computing resources, QC devices, optimizer parameters. The input schema: { \"version\" : \"string\" , \"runMode\" : \"string\" , \"molFile\" : \"string\" , \"modelVersion\" : \"string\" , \"experimentName\" : \"string\" , \"optParams\" : { \"qa\" : { \"shots\" : \"int\" , \"embed_method\" : \"string\" }, \"sa\" : { \"shots\" : \"int\" , \"notes\" : \"string\" } }, \"modelParams\" : { \"M\" : \"int []\" , \"D\" : \"int []\" , \"A\" : \"int []\" , \"HQ\" : \"int []\" , }, \"devicesArns\" : \"string []\" , \"hpcResources\" : \"[int, int] []\" , } Definition: version : the version of input schema , current only support value is : '1' runModel : ALL | HPC | QC , default : 'ALL' molFile : s3 url of the file modelVersion : any string , default : 'latest' experimentName : any string hpcResources : 2 - d array , e . g : 2 vCPU /4GiB memory and 4 vCPU/ 8 GiB memory : [[ 2 , 4 ], [ 4 , 8 ]] A typical and default(if input json is {} ) input: { \"version\" : \"1\" , \"runMode\" : \"ALL\" , \"optParams\" : { \"qa\" : { \"shots\" : 1000 }, \"sa\" : { \"shots\" : 1000 } }, \"modelParams\" : { \"M\" : [ 1 , 2 , 3 , 4 ], \"D\" : [ 4 ], \"A\" : [ 300 ], \"HQ\" : [ 200 ] }, \"devicesArns\" : [ \"arn:aws:braket:::device/qpu/d-wave/DW_2000Q_6\" , \"arn:aws:braket:::device/qpu/d-wave/Advantage_system4\" ], \"hpcResources\" : [ [ 2 , 2 ], [ 4 , 4 ], [ 8 , 8 ], [ 16 , 16 ] ] } View dashboard Dashboard link If you run Step Functions multi-times, by default, the dashboard average metrics of all executions. You can click a item in the experiment hist table in the left-upper corner to view the result of a specific execution. Trouble shooting Step Functions failed because of \"Check Input\" step failed. If the input json not is passed the input validation, this step fails. Check the errorMessage of the step, fix your input. Step Functions failed because of Lambda.TooManyRequestsException . If you run the StepFunctions with high a frequency, you may get this error, you can wait several seconds and retry. Dashboard can not be displayed, the error message complains permission error when accessing data in S3 bucket. Go to quicksight admin , in QuickSight access to AWS services , make sure your S3 bucket is checked.","title":"Batch Evaluation"},{"location":"workshop/a-molecule-unfolding/batch-test/#run-batch-test","text":"We will run batch test through AWS Step Functions workflow and view the result via AWS QuickSight dashboard","title":"Run Batch Test"},{"location":"workshop/a-molecule-unfolding/batch-test/#get-step-functions-link-from-deployment-output","text":"","title":"Get Step Functions link from deployment output"},{"location":"workshop/a-molecule-unfolding/batch-test/#start-execution","text":"All input fields of the input json is optional, but you can customize anything about model parameters, computing resources, QC devices, optimizer parameters. The input schema: { \"version\" : \"string\" , \"runMode\" : \"string\" , \"molFile\" : \"string\" , \"modelVersion\" : \"string\" , \"experimentName\" : \"string\" , \"optParams\" : { \"qa\" : { \"shots\" : \"int\" , \"embed_method\" : \"string\" }, \"sa\" : { \"shots\" : \"int\" , \"notes\" : \"string\" } }, \"modelParams\" : { \"M\" : \"int []\" , \"D\" : \"int []\" , \"A\" : \"int []\" , \"HQ\" : \"int []\" , }, \"devicesArns\" : \"string []\" , \"hpcResources\" : \"[int, int] []\" , } Definition: version : the version of input schema , current only support value is : '1' runModel : ALL | HPC | QC , default : 'ALL' molFile : s3 url of the file modelVersion : any string , default : 'latest' experimentName : any string hpcResources : 2 - d array , e . g : 2 vCPU /4GiB memory and 4 vCPU/ 8 GiB memory : [[ 2 , 4 ], [ 4 , 8 ]] A typical and default(if input json is {} ) input: { \"version\" : \"1\" , \"runMode\" : \"ALL\" , \"optParams\" : { \"qa\" : { \"shots\" : 1000 }, \"sa\" : { \"shots\" : 1000 } }, \"modelParams\" : { \"M\" : [ 1 , 2 , 3 , 4 ], \"D\" : [ 4 ], \"A\" : [ 300 ], \"HQ\" : [ 200 ] }, \"devicesArns\" : [ \"arn:aws:braket:::device/qpu/d-wave/DW_2000Q_6\" , \"arn:aws:braket:::device/qpu/d-wave/Advantage_system4\" ], \"hpcResources\" : [ [ 2 , 2 ], [ 4 , 4 ], [ 8 , 8 ], [ 16 , 16 ] ] }","title":"Start Execution"},{"location":"workshop/a-molecule-unfolding/batch-test/#view-dashboard","text":"Dashboard link If you run Step Functions multi-times, by default, the dashboard average metrics of all executions. You can click a item in the experiment hist table in the left-upper corner to view the result of a specific execution.","title":"View dashboard"},{"location":"workshop/a-molecule-unfolding/batch-test/#trouble-shooting","text":"Step Functions failed because of \"Check Input\" step failed. If the input json not is passed the input validation, this step fails. Check the errorMessage of the step, fix your input. Step Functions failed because of Lambda.TooManyRequestsException . If you run the StepFunctions with high a frequency, you may get this error, you can wait several seconds and retry. Dashboard can not be displayed, the error message complains permission error when accessing data in S3 bucket. Go to quicksight admin , in QuickSight access to AWS services , make sure your S3 bucket is checked.","title":"Trouble shooting"},{"location":"workshop/a-molecule-unfolding/molecule-unfolding/","text":"We are trying to implement an important process in drug discovery according to following publication, video or reports. References Publication: Quantum Molecular Unfolding Video: Molecular Unfolding with Quantum Annealing","title":"Background"},{"location":"workshop/a-molecule-unfolding/molecule-unfolding/#references","text":"Publication: Quantum Molecular Unfolding Video: Molecular Unfolding with Quantum Annealing","title":"References"},{"location":"workshop/a-molecule-unfolding/notebook-experiment/","text":"Molecular Docking (MD) is an important step of the drug discovery process which aims at calculating the preferred position and shape of one molecule to a second when they are bound to each other. This step focuses on computationally simulating the molecular recognition process. It aims to achieve an optimized conformation for both the protein and ligand and relative orientation between protein and ligand such that the free energy of the overall system is minimized. Molecular Docking 1 In this work, The protein or the pocket is considered as a rigid structure. The ligand is considered as a flexible set of atoms. There are usually three main phases in MD: Ligand expansion Identification of the rotatable bonds Internal distances maximization Remove tool related bias (e.g. smile-to-3D) Initial Placement Ligand main fragments decomposition Ligand initial poses identification Placement of the ligand into the pocket with rigid roto-translations Shape Refinement Use of the rotatable bonds to modify the ligand shape and to match the protein pocket Docking score maximization In this work, actually the first phase, ligand expansion or the molecular unfolding (MU), is focused and implemented using quantum annealer. This phase is important for improving docking. In fact, an initial pose of the ligand that is set a priori may introduce shape bias affecting the final quality of the docking. MU is the technology used for removing such initial bias. Notebook Overview Go to the deployment output page in your cloudformation and open the link for your notebook Output of Cloudformation Please open the notebook in source/src/molecular-folding/molecular_unfolding.ipynb and make sure that the kernel for this notebook is qcenv . Environment for Experiment Navigate the whole notebook and you can find that it consists of four Steps: Steps Contents Step1: Prepare Data prepare molecular data for experiments Step2: Build Model build model for molecular unfolding Step3: Optimize Configuration run optimization to find the configuration Step4: PostProcess Result post process the results for evaluation and visualization Prepare Data In this part, we load the raw molecule data for experiment. The 117 ligand was put in the repository. We assign the relative path to raw_path . The s3_bucket and prefix are used to store the optimization results. We can use the one created with the cloudformation for convenience. Process Molecule Data After running this block, the processed data will be saved as qmu_117_ideal_data_latest.pickle and data_path will be updated. We can see that this molecule has 23 rotatable bonds. Build Model In this part, we build the Quadratic Unconstrained Binary Optimization (QUBO) model for molecular unfolding. First, we set the following parameters and initialize the QMUQUBO object. Parameter Description Value A penalty scalar 300 hubo_qubo_val energy penalty of make_quadratic() 200 M number of torsions for molecular unfolding [1, max number of rotatable bonds] D angle precision of rotation 8 method the method of building model 'pre-calc': calculate the score in advance Build QUBO Model We can see from the image that we use the 'pre-calc' method to build the model. This molecule has 23 rotatable bonds and we only test 2 of them, so we set the M to 2. And we want the angle to become \\(45^o\\) , so we set the D to 8 (i.e., \\(8=360^o/45^o\\) ). The A and hubo_qubo_val are test from experiments. We can use the following method to check the properties of model. This way, we can build many models conveniently. After that, we save the model and update the value of model_path . Describe and Save QUBO Model Notice The following content is the technical details for building model Problem Definition In this problem, the ligand is considered as a flexible set of atoms. Strictly speaking, it can be seen as a set of chemical bonds (edges). These bonds have fixed length and only a subset of them are rotatable. Because there are some rotatable bonds (torsions) , the molecule is split into different disjointed fragments. Take one bond for instance, the rightmost rotatable one, it splits the molecule into the left and right fragments. These fragments can rotate independently from each other around the axis of the bond. This idea is graphically reported in the following figure. Rotatable Bonds 1 As it indicates, the objective of MU is to find the shape of the ligand that can maximizes the molecular volume. The shape of the ligand can be expressed as the unfolded shape of the ligand (the torsion configuration of all the rotatable bonds). Formulation Suppose the ligand has \\(M\\) torsions, from \\(T_i\\) to \\(T_M\\) , and each torsion must have the angle of rotation \\(\\theta\\) . Multiple Torsion The objective of this model is to find the unfolded torsion configuration \\({\\Theta}^{unfold}\\) which can maximizes the sum of distances \\(D(\\Theta)\\) . \\[ {\\Theta}^{unfold} = [\\theta^{unfold}_1, \\theta^{unfold}_2, ../..., \\theta^{unfold}_M] \\] \\[ D(\\Theta) = \\sum_{a,b}D_{a,b}(\\theta)^2 \\] The \\(D_{a,b}(\\theta)^2\\) is \\(|| \\overrightarrow{a}_0 - R(\\theta)\\overrightarrow{b}_0||^2\\) . This is the distance between fragment a and b. \\(R(\\theta)\\) is the rotation matrix associated the torsion angle \\(\\theta\\) . Two Fragment with One Torsion Since this is the problem of portfolio optimization, the final configuration can be the combination of any angle of any torsion. However, there are some constraints for applying it to real problem: constraint-1 In terms of the limitation of computation resource, the torsion cannot have the rotation with infinitely small precision. This means that there are limited candidates of rotation angles for each torsion. Suppose we have \\(M\\) torsions and they have the same precision of rotation angle : \\(\\Delta\\theta\\) . This means that we need \\(d\\) variables for each torsion: \\[ d = \\frac{2\\pi}{\\Delta\\theta} \\] For the whole model, we need \\(n = d \\times M\\) binary variables \\(x_{ik}\\) to represent all the combinations. For example, for the torsion \\(T_i\\) , its torsion angle \\(\\theta_i\\) can have \\(d\\) possible values: \\[ \\theta_i = [\\theta_i^1,\\theta_i^2,\\theta_i^3, ..., \\theta_i^d] \\] constraint-2 If we only consider the distance, the final result or configuration may have multiple results from the same torsion as long as this combination means smaller distance. For example, there may be two binary variables of the same torsion, \\(T_i\\) , in the final result: \\[ {\\Theta}^{unfold} = [\\theta^2_1, \\theta^4_1, ../..., \\theta^3_M] \\] This cannot happen in real world. \\(T_1\\) can only have one of \\(d\\) angles finally. So we need to integrate the following constraint into our final model: \\[ \\displaystyle\\sum\\limits_{k=1}^{d} x_{ik} = 1 \\] With these two constraints, this problem can be formulated as the high-order unconstrained binary optimization (HUBO). \\[ O(x_{ik}) = A\\displaystyle\\sum\\limits_i (\\displaystyle\\sum\\limits_{k=1}^d x_{ik}-1)^2 - \\displaystyle\\sum\\limits_{a,b} D_{ab} (\\theta)^2 \\] The first part is the constraint for each torsion. If one torsion has more than one angles at last, we will add the punishment term \\(A\\) . However, in this implementation we calculate the distance-pair under different configuration in advance. This means that we use the absolute distance instead: \\[ O(x_{ik}) = A\\displaystyle\\sum\\limits_i (\\displaystyle\\sum\\limits_{k=1}^d x_{ik}-1)^2 - \\displaystyle\\sum\\limits_{a,b} |D_{ab} (\\theta)| \\] The Code for Model We have implemented this model in source/src/molecualr-unfolding/untiliy/QMUQUBO.py . We initialize the variables using the following logic: Notice The following codes are for describing the ideas to build the model. We can find similar codes in the source code The Logic for Defining the Variables The above code indicates that we have 4 torsions from \\(x\\_1\\_?\\) to \\(x\\_4\\_?\\) . Each torsion has four optional rotation angles from \\(0^o\\) to \\(270^o\\) . For example, \\(x\\_3\\_2\\) means that the torsion 3 rotates \\(180^o\\) . For constraints, we use the following logic to implement: The Logic for Defining the Constraints As we analyze before, the model does not which variables belong to the same physical torsion. For example, \\(x\\_1\\_1\\) , \\(x\\_1\\_2\\) , \\(x\\_1\\_3\\) and \\(x\\_1\\_4\\) belong to the same torsion. The model cannot let only one of them become \\(1\\) . If the model choose multiple of them, we must punish it. As the figure shown, when the model choose more than one variables of \\(x\\_1\\_?\\) to become \\(1\\) , we give it the punishment term \\(600\\) . Most importantly, we use \\(calc\\_distance\\_func\\) to calculate \\(|D_{ab} (\\theta)|\\) under different \\(\\theta\\) . The Logic for Calculating the Distance between Fragments. Quantum Annealing The quantum annealing (QA) can be seen as a variation of the simulated annealing (SA). Both QA and SA are meta-heuristic technique for address challenging combinatorial problems. QA uses the quantum fluctuation to explore the configuration space instead of thermal effects. Here, we use Amazon Braket API to access the Canadian company D-Wave. This annealer is implemented using superconductive qubits. Natively, the quadratic unconstrained binary optimization (QUBO) can be solved using quantum annealer: \\[ O(x) = \\displaystyle\\sum\\limits_i h_i x_i + \\displaystyle\\sum_{i>j} J_{i,j} x_i x_j \\] In QUBO form, \\(x_i \\in \\{0, 1\\}\\) are binary variables. We can consider it as the angle that we choose for a particular torsion. \\(h_i\\) and \\(J_{i,j}\\) can be considered as the values encoding the optimization task when we use corresponding angles. However, in our task, it is common that there are more than one torsion between fragments, we model it as the high-order quadratic unconstrained binary optimization (HUBO) problem: \\[ O(x) = \\displaystyle\\sum\\limits_i \\alpha_i x_i + \\displaystyle\\sum_{i,j} \\beta_{i,j} x_i x_j + \\displaystyle\\sum_{i,j,k} \\gamma_{i,j,k} x_i x_j x_k + ../... \\] It is often possible to convert HUBOs to QUBOs by using some tricks, like adding new ancillary binary variables to replace high-order term. In practice, we use the API \\(make \\_ quadratic()\\) in D-Wave software package to make this conversion. As the image shown, some high-order term of HUBO, like \\(('x\\_1\\_1','x\\_2\\_1','x\\_3\\_1')\\) , have been transformed to binary terms in QUBO. We only highlight some of them. Congratulations! We have already prepared the model and it is time to find the optimized configuration. Optimize Configuration In this part, we use SA and QA to find the optimized configuration of molecular unfolding. At first, we load the model file using QMUQUBO object. Load model file with one QUBO model We can see the parameters of this model, with M equaling 2, D equaling 8, A equaling 300 and hubo_qubo_val equaling 200. Actually, we can contain multiple models in this file just by giving multiple values for one parameter when creating models. Load model file with two QUBO models This time, we can see that this model file contains two QUBO models with different M values. Then, we need use model_name to get the model for experiments. Get model using the model name We can see that we want to carry out experiment with the QUBO model with M equaling 2. After that, we set the parameters for optimization. Parameter Description Value method annealing method for QUBO problem 'dwave-sa': use the simulated annealer in ocean toolkit 'dwave-qa': use the quantum annealer shots number of reads, refer to dwave-sa and dwave-qa for details 1 to 10,000 bucket the s3 bucket to store your results - prefix the name of the folder in your s3 bucket - device the arn name to run your quantum annealing 'arn:aws:braket:::device/qpu/d-wave/Advantage_system4' 'arn:aws:braket:::device/qpu/d-wave/DW_2000Q_6' Then, we can run the SA for this problem: We can tell from the image that we set the number of shots for SA to 1000. The result is saved as the local file ./sa_result.pickle. Alternatively, we can use QA to solve this problem: In this QA, we set the number of shots to 1000 and choose the Advantage_System4.1 as the QPU. In addition, the results are saved to your bucket automatically and you can get the task id for future process. Finally, we can compare the execution time between SA and QA : We can tell from the image that SA needs 174.2 seconds and QA needs 7.7 seconds to find solution. Warning Be careful to increase the number of shots for SA to avoid long run time Analyze The Quality After some time, we get the results. As the result indicates, the best answer of quantum annealer only occurs once. This does not always indicate an error. It is actually the characteristic of the problem or how the problem is formulated. Because we have different linear and quadratic terms that vary by many orders of magnitude. If we set change value of A to some smaller number, like 10 or 100, more occurrences of the best answer will be observed. However, these answers usually break the constraints. For more information about this phenomenon, please refer to this Link . Post-Process Result In this part, we post process the optimizing results for evaluation and visualization. At first, we prepare the following parameters: Parameter Description Value method annealing method for QUBO problem 'dwave-sa': use the simulated annealer in ocean toolkit 'dwave-qa': use the quantum annealer raw_path the path for the original molecule file './molecule-data/117_ideal.mol2' in this example data_path the path for the processed molecule file './qmu_117_ideal_data_latest.mol2' in this example bucket the s3 bucket to store your results - prefix the name of the folder in your s3 bucket - task_id the id for your quantum annealing task '2b5a3b05-1a0e-443a-852c-4ec422a10e59' in this example Then we can run the post-process using ResultParser object for SA: Post process for SA In the first block, we can see the local time for SA is around 174 seconds. With the generate_optimize_pts() method, the final 3D points after unfolding will be generated and saved as json file and mol2 files. The last block shows the optimizing results which are also stored in json files. It shows that the optimized result gains 1.0212x increase in volume. The value for unfolding_results indicates that the rotatable bond 15 should rotate \\(270^o\\) ( \\(360/8*(7-1)\\) ) and the rotatable bond 14 should rotate \\(315^o\\) ( \\(360/8*(8-1)\\) ). At the same time, you can run the post-process for QA: Post process for QA In the first block, we can see that there many types of time metrics for running QA. This task has the local time of 7.7 s, which means the time between calling the api and getting the annealing result. The task time time is the metric from the json file in bucket. We can also see the qpu total time and qpu access time representing the actual time running in the QPU. Please refer to Operation and Timing for details. In same way, the optimized results are translated the 3D points and saved as local json and mol2 files. The result indicates that QA gains 1.021x increase in volume. Finally, We can open folders for the optimized results: Optimize Results We can the json result and mol2 file of SA and QA are stored in this place. If we carry out more experiments, more results with time stamp are stored incrementally. For visualization, we can upload the result 117_ideal_dwave-qa_20220216-05.mol2 into online viewer tool to see the result: Visualization References Wiki: Molecular Docking Publication: Quantum Molecular Unfolding Video: Molecular Unfolding with Quantum Annealing","title":"Notebook Experiment"},{"location":"workshop/a-molecule-unfolding/notebook-experiment/#notebook-overview","text":"Go to the deployment output page in your cloudformation and open the link for your notebook Output of Cloudformation Please open the notebook in source/src/molecular-folding/molecular_unfolding.ipynb and make sure that the kernel for this notebook is qcenv . Environment for Experiment Navigate the whole notebook and you can find that it consists of four Steps: Steps Contents Step1: Prepare Data prepare molecular data for experiments Step2: Build Model build model for molecular unfolding Step3: Optimize Configuration run optimization to find the configuration Step4: PostProcess Result post process the results for evaluation and visualization","title":"Notebook Overview"},{"location":"workshop/a-molecule-unfolding/notebook-experiment/#prepare-data","text":"In this part, we load the raw molecule data for experiment. The 117 ligand was put in the repository. We assign the relative path to raw_path . The s3_bucket and prefix are used to store the optimization results. We can use the one created with the cloudformation for convenience. Process Molecule Data After running this block, the processed data will be saved as qmu_117_ideal_data_latest.pickle and data_path will be updated. We can see that this molecule has 23 rotatable bonds.","title":"Prepare Data"},{"location":"workshop/a-molecule-unfolding/notebook-experiment/#build-model","text":"In this part, we build the Quadratic Unconstrained Binary Optimization (QUBO) model for molecular unfolding. First, we set the following parameters and initialize the QMUQUBO object. Parameter Description Value A penalty scalar 300 hubo_qubo_val energy penalty of make_quadratic() 200 M number of torsions for molecular unfolding [1, max number of rotatable bonds] D angle precision of rotation 8 method the method of building model 'pre-calc': calculate the score in advance Build QUBO Model We can see from the image that we use the 'pre-calc' method to build the model. This molecule has 23 rotatable bonds and we only test 2 of them, so we set the M to 2. And we want the angle to become \\(45^o\\) , so we set the D to 8 (i.e., \\(8=360^o/45^o\\) ). The A and hubo_qubo_val are test from experiments. We can use the following method to check the properties of model. This way, we can build many models conveniently. After that, we save the model and update the value of model_path . Describe and Save QUBO Model Notice The following content is the technical details for building model","title":"Build Model"},{"location":"workshop/a-molecule-unfolding/notebook-experiment/#problem-definition","text":"In this problem, the ligand is considered as a flexible set of atoms. Strictly speaking, it can be seen as a set of chemical bonds (edges). These bonds have fixed length and only a subset of them are rotatable. Because there are some rotatable bonds (torsions) , the molecule is split into different disjointed fragments. Take one bond for instance, the rightmost rotatable one, it splits the molecule into the left and right fragments. These fragments can rotate independently from each other around the axis of the bond. This idea is graphically reported in the following figure. Rotatable Bonds 1 As it indicates, the objective of MU is to find the shape of the ligand that can maximizes the molecular volume. The shape of the ligand can be expressed as the unfolded shape of the ligand (the torsion configuration of all the rotatable bonds).","title":"Problem Definition"},{"location":"workshop/a-molecule-unfolding/notebook-experiment/#formulation","text":"Suppose the ligand has \\(M\\) torsions, from \\(T_i\\) to \\(T_M\\) , and each torsion must have the angle of rotation \\(\\theta\\) . Multiple Torsion The objective of this model is to find the unfolded torsion configuration \\({\\Theta}^{unfold}\\) which can maximizes the sum of distances \\(D(\\Theta)\\) . \\[ {\\Theta}^{unfold} = [\\theta^{unfold}_1, \\theta^{unfold}_2, ../..., \\theta^{unfold}_M] \\] \\[ D(\\Theta) = \\sum_{a,b}D_{a,b}(\\theta)^2 \\] The \\(D_{a,b}(\\theta)^2\\) is \\(|| \\overrightarrow{a}_0 - R(\\theta)\\overrightarrow{b}_0||^2\\) . This is the distance between fragment a and b. \\(R(\\theta)\\) is the rotation matrix associated the torsion angle \\(\\theta\\) . Two Fragment with One Torsion Since this is the problem of portfolio optimization, the final configuration can be the combination of any angle of any torsion. However, there are some constraints for applying it to real problem:","title":"Formulation"},{"location":"workshop/a-molecule-unfolding/notebook-experiment/#constraint-1","text":"In terms of the limitation of computation resource, the torsion cannot have the rotation with infinitely small precision. This means that there are limited candidates of rotation angles for each torsion. Suppose we have \\(M\\) torsions and they have the same precision of rotation angle : \\(\\Delta\\theta\\) . This means that we need \\(d\\) variables for each torsion: \\[ d = \\frac{2\\pi}{\\Delta\\theta} \\] For the whole model, we need \\(n = d \\times M\\) binary variables \\(x_{ik}\\) to represent all the combinations. For example, for the torsion \\(T_i\\) , its torsion angle \\(\\theta_i\\) can have \\(d\\) possible values: \\[ \\theta_i = [\\theta_i^1,\\theta_i^2,\\theta_i^3, ..., \\theta_i^d] \\]","title":"constraint-1"},{"location":"workshop/a-molecule-unfolding/notebook-experiment/#constraint-2","text":"If we only consider the distance, the final result or configuration may have multiple results from the same torsion as long as this combination means smaller distance. For example, there may be two binary variables of the same torsion, \\(T_i\\) , in the final result: \\[ {\\Theta}^{unfold} = [\\theta^2_1, \\theta^4_1, ../..., \\theta^3_M] \\] This cannot happen in real world. \\(T_1\\) can only have one of \\(d\\) angles finally. So we need to integrate the following constraint into our final model: \\[ \\displaystyle\\sum\\limits_{k=1}^{d} x_{ik} = 1 \\] With these two constraints, this problem can be formulated as the high-order unconstrained binary optimization (HUBO). \\[ O(x_{ik}) = A\\displaystyle\\sum\\limits_i (\\displaystyle\\sum\\limits_{k=1}^d x_{ik}-1)^2 - \\displaystyle\\sum\\limits_{a,b} D_{ab} (\\theta)^2 \\] The first part is the constraint for each torsion. If one torsion has more than one angles at last, we will add the punishment term \\(A\\) . However, in this implementation we calculate the distance-pair under different configuration in advance. This means that we use the absolute distance instead: \\[ O(x_{ik}) = A\\displaystyle\\sum\\limits_i (\\displaystyle\\sum\\limits_{k=1}^d x_{ik}-1)^2 - \\displaystyle\\sum\\limits_{a,b} |D_{ab} (\\theta)| \\]","title":"constraint-2"},{"location":"workshop/a-molecule-unfolding/notebook-experiment/#the-code-for-model","text":"We have implemented this model in source/src/molecualr-unfolding/untiliy/QMUQUBO.py . We initialize the variables using the following logic: Notice The following codes are for describing the ideas to build the model. We can find similar codes in the source code The Logic for Defining the Variables The above code indicates that we have 4 torsions from \\(x\\_1\\_?\\) to \\(x\\_4\\_?\\) . Each torsion has four optional rotation angles from \\(0^o\\) to \\(270^o\\) . For example, \\(x\\_3\\_2\\) means that the torsion 3 rotates \\(180^o\\) . For constraints, we use the following logic to implement: The Logic for Defining the Constraints As we analyze before, the model does not which variables belong to the same physical torsion. For example, \\(x\\_1\\_1\\) , \\(x\\_1\\_2\\) , \\(x\\_1\\_3\\) and \\(x\\_1\\_4\\) belong to the same torsion. The model cannot let only one of them become \\(1\\) . If the model choose multiple of them, we must punish it. As the figure shown, when the model choose more than one variables of \\(x\\_1\\_?\\) to become \\(1\\) , we give it the punishment term \\(600\\) . Most importantly, we use \\(calc\\_distance\\_func\\) to calculate \\(|D_{ab} (\\theta)|\\) under different \\(\\theta\\) . The Logic for Calculating the Distance between Fragments.","title":"The Code for Model"},{"location":"workshop/a-molecule-unfolding/notebook-experiment/#quantum-annealing","text":"The quantum annealing (QA) can be seen as a variation of the simulated annealing (SA). Both QA and SA are meta-heuristic technique for address challenging combinatorial problems. QA uses the quantum fluctuation to explore the configuration space instead of thermal effects. Here, we use Amazon Braket API to access the Canadian company D-Wave. This annealer is implemented using superconductive qubits. Natively, the quadratic unconstrained binary optimization (QUBO) can be solved using quantum annealer: \\[ O(x) = \\displaystyle\\sum\\limits_i h_i x_i + \\displaystyle\\sum_{i>j} J_{i,j} x_i x_j \\] In QUBO form, \\(x_i \\in \\{0, 1\\}\\) are binary variables. We can consider it as the angle that we choose for a particular torsion. \\(h_i\\) and \\(J_{i,j}\\) can be considered as the values encoding the optimization task when we use corresponding angles. However, in our task, it is common that there are more than one torsion between fragments, we model it as the high-order quadratic unconstrained binary optimization (HUBO) problem: \\[ O(x) = \\displaystyle\\sum\\limits_i \\alpha_i x_i + \\displaystyle\\sum_{i,j} \\beta_{i,j} x_i x_j + \\displaystyle\\sum_{i,j,k} \\gamma_{i,j,k} x_i x_j x_k + ../... \\] It is often possible to convert HUBOs to QUBOs by using some tricks, like adding new ancillary binary variables to replace high-order term. In practice, we use the API \\(make \\_ quadratic()\\) in D-Wave software package to make this conversion. As the image shown, some high-order term of HUBO, like \\(('x\\_1\\_1','x\\_2\\_1','x\\_3\\_1')\\) , have been transformed to binary terms in QUBO. We only highlight some of them. Congratulations! We have already prepared the model and it is time to find the optimized configuration.","title":"Quantum Annealing"},{"location":"workshop/a-molecule-unfolding/notebook-experiment/#optimize-configuration","text":"In this part, we use SA and QA to find the optimized configuration of molecular unfolding. At first, we load the model file using QMUQUBO object. Load model file with one QUBO model We can see the parameters of this model, with M equaling 2, D equaling 8, A equaling 300 and hubo_qubo_val equaling 200. Actually, we can contain multiple models in this file just by giving multiple values for one parameter when creating models. Load model file with two QUBO models This time, we can see that this model file contains two QUBO models with different M values. Then, we need use model_name to get the model for experiments. Get model using the model name We can see that we want to carry out experiment with the QUBO model with M equaling 2. After that, we set the parameters for optimization. Parameter Description Value method annealing method for QUBO problem 'dwave-sa': use the simulated annealer in ocean toolkit 'dwave-qa': use the quantum annealer shots number of reads, refer to dwave-sa and dwave-qa for details 1 to 10,000 bucket the s3 bucket to store your results - prefix the name of the folder in your s3 bucket - device the arn name to run your quantum annealing 'arn:aws:braket:::device/qpu/d-wave/Advantage_system4' 'arn:aws:braket:::device/qpu/d-wave/DW_2000Q_6' Then, we can run the SA for this problem: We can tell from the image that we set the number of shots for SA to 1000. The result is saved as the local file ./sa_result.pickle. Alternatively, we can use QA to solve this problem: In this QA, we set the number of shots to 1000 and choose the Advantage_System4.1 as the QPU. In addition, the results are saved to your bucket automatically and you can get the task id for future process. Finally, we can compare the execution time between SA and QA : We can tell from the image that SA needs 174.2 seconds and QA needs 7.7 seconds to find solution. Warning Be careful to increase the number of shots for SA to avoid long run time","title":"Optimize Configuration"},{"location":"workshop/a-molecule-unfolding/notebook-experiment/#analyze-the-quality","text":"After some time, we get the results. As the result indicates, the best answer of quantum annealer only occurs once. This does not always indicate an error. It is actually the characteristic of the problem or how the problem is formulated. Because we have different linear and quadratic terms that vary by many orders of magnitude. If we set change value of A to some smaller number, like 10 or 100, more occurrences of the best answer will be observed. However, these answers usually break the constraints. For more information about this phenomenon, please refer to this Link .","title":"Analyze The Quality"},{"location":"workshop/a-molecule-unfolding/notebook-experiment/#post-process-result","text":"In this part, we post process the optimizing results for evaluation and visualization. At first, we prepare the following parameters: Parameter Description Value method annealing method for QUBO problem 'dwave-sa': use the simulated annealer in ocean toolkit 'dwave-qa': use the quantum annealer raw_path the path for the original molecule file './molecule-data/117_ideal.mol2' in this example data_path the path for the processed molecule file './qmu_117_ideal_data_latest.mol2' in this example bucket the s3 bucket to store your results - prefix the name of the folder in your s3 bucket - task_id the id for your quantum annealing task '2b5a3b05-1a0e-443a-852c-4ec422a10e59' in this example Then we can run the post-process using ResultParser object for SA: Post process for SA In the first block, we can see the local time for SA is around 174 seconds. With the generate_optimize_pts() method, the final 3D points after unfolding will be generated and saved as json file and mol2 files. The last block shows the optimizing results which are also stored in json files. It shows that the optimized result gains 1.0212x increase in volume. The value for unfolding_results indicates that the rotatable bond 15 should rotate \\(270^o\\) ( \\(360/8*(7-1)\\) ) and the rotatable bond 14 should rotate \\(315^o\\) ( \\(360/8*(8-1)\\) ). At the same time, you can run the post-process for QA: Post process for QA In the first block, we can see that there many types of time metrics for running QA. This task has the local time of 7.7 s, which means the time between calling the api and getting the annealing result. The task time time is the metric from the json file in bucket. We can also see the qpu total time and qpu access time representing the actual time running in the QPU. Please refer to Operation and Timing for details. In same way, the optimized results are translated the 3D points and saved as local json and mol2 files. The result indicates that QA gains 1.021x increase in volume. Finally, We can open folders for the optimized results: Optimize Results We can the json result and mol2 file of SA and QA are stored in this place. If we carry out more experiments, more results with time stamp are stored incrementally. For visualization, we can upload the result 117_ideal_dwave-qa_20220216-05.mol2 into online viewer tool to see the result: Visualization","title":"Post-Process Result"},{"location":"workshop/a-molecule-unfolding/notebook-experiment/#references","text":"Wiki: Molecular Docking Publication: Quantum Molecular Unfolding Video: Molecular Unfolding with Quantum Annealing","title":"References"},{"location":"workshop/a-molecule-unfolding/test-your-own-model/","text":"Batch Evaluate Your Own Model You have two options to batch test your own model Batch Evaluate your own mol2 file with out code changes Fully customize the test code Batch Evaluate your own mol2 file with out code changes If you have your own mol2 file, you want to batch test it, you can follow below steps: Upload your mol2 file to a S3 bucket, bucket name must be braket-* or amazon-braket-* . Specify S3 uri of your mol2 file as the value of molFile in the Step Functions input json json { \"molFile\" : \"<s3 uri of your mol2 file>\" } The full input parameters and schema, please refer to batch test Then Start Execution the Step functions. Fully customize the test code This solution is an open source project under Apache License Version 2.0. You can leverage it as your base code, make changes on it. If you want to fully customize the test code, follow below steps to re-deploy the whole stack from CDK. Fork the github repository of this solution to your own git repository. Clone the project to your own workspace, make changes to the source code. Update quicksight_user and default_code_repository in file source/cdk.context.json . Check CloudFormation in your AWS account, make sure you do not have a stack named QCStack in your deployment region. Make sure you have AWS CDK install in your workspace. You can follow this doc cdk getting_started to install and bootstrap CDK. Make sure you have docker running in your workspace. You can follow this doc docker install to install docker. Deploy changes to your AWS account via CDK. ```sh cd source npm run deploy ``` Wait for the deployment to complete. Get output links from CloudFormation output, the links include: Step Functions URL QuickSight Dashboard link Notebook URL Run Step Functions via your custom parameters. View result through QuickSight dashboard.","title":"Evaluate Your Own Model"},{"location":"workshop/a-molecule-unfolding/test-your-own-model/#batch-evaluate-your-own-model","text":"You have two options to batch test your own model Batch Evaluate your own mol2 file with out code changes Fully customize the test code","title":"Batch Evaluate Your Own Model"},{"location":"workshop/a-molecule-unfolding/test-your-own-model/#batch-evaluate-your-own-mol2-file-with-out-code-changes","text":"If you have your own mol2 file, you want to batch test it, you can follow below steps: Upload your mol2 file to a S3 bucket, bucket name must be braket-* or amazon-braket-* . Specify S3 uri of your mol2 file as the value of molFile in the Step Functions input json json { \"molFile\" : \"<s3 uri of your mol2 file>\" } The full input parameters and schema, please refer to batch test Then Start Execution the Step functions.","title":"Batch Evaluate your own mol2 file with out code changes"},{"location":"workshop/a-molecule-unfolding/test-your-own-model/#fully-customize-the-test-code","text":"This solution is an open source project under Apache License Version 2.0. You can leverage it as your base code, make changes on it. If you want to fully customize the test code, follow below steps to re-deploy the whole stack from CDK. Fork the github repository of this solution to your own git repository. Clone the project to your own workspace, make changes to the source code. Update quicksight_user and default_code_repository in file source/cdk.context.json . Check CloudFormation in your AWS account, make sure you do not have a stack named QCStack in your deployment region. Make sure you have AWS CDK install in your workspace. You can follow this doc cdk getting_started to install and bootstrap CDK. Make sure you have docker running in your workspace. You can follow this doc docker install to install docker. Deploy changes to your AWS account via CDK. ```sh cd source npm run deploy ``` Wait for the deployment to complete. Get output links from CloudFormation output, the links include: Step Functions URL QuickSight Dashboard link Notebook URL Run Step Functions via your custom parameters. View result through QuickSight dashboard.","title":"Fully customize the test code"}]}